{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import os,sys\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sb\n",
    "import pandas as pd\n",
    "import dill\n",
    "import flow_ssl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from flow_ssl.data import GAS, HEPMASS, MINIBOONE\n",
    "from flow_ssl.data.nlp_datasets import AG_News,YAHOO\n",
    "from torch.utils.data import DataLoader\n",
    "#from oil.datasetup.dataloaders import getLabLoader,classBalancedSampleIndices\n",
    "from oil.datasetup.datasets import split_dataset\n",
    "from oil.utils.utils import FixedNumpySeed\n",
    "from oil.model_trainers.graphssl import GraphSSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748342\n",
      "140000\n"
     ]
    }
   ],
   "source": [
    "H = HEPMASS(os.path.expanduser('~/datasets/UCI/hepmass/'),train=True)\n",
    "Ht = HEPMASS(os.path.expanduser('~/datasets/UCI/hepmass/'),train=False)\n",
    "M = MINIBOONE(os.path.expanduser('~/datasets/UCI/miniboone/'),train=True)\n",
    "Mt = MINIBOONE(os.path.expanduser('~/datasets/UCI/miniboone/'),train=False)\n",
    "A = AG_News(os.path.expanduser('~/datasets/AGNEWS/'),train=True)\n",
    "At = AG_News(os.path.expanduser('~/datasets/AGNEWS/'),train=False)\n",
    "Ya = YAHOO(os.path.expanduser('~/datasets/YAHOO/'),train=True)\n",
    "Yt = YAHOO(os.path.expanduser('~/datasets/YAHOO/'),train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oh(a, num_classes):\n",
    "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = np.load('ag_news_train.npz')\n",
    "# x_train = train_data['encodings']\n",
    "# y_train = train_data['labels']\n",
    "# test_data = np.load('ag_news_test.npz')\n",
    "# x_test = test_data['encodings']\n",
    "# y_test = test_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 5000#3000\n",
    "\n",
    "unlab_size=20000#5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = H.trn\n",
    "X_test = H.tst\n",
    "y_train = H.y_trn.astype(int)\n",
    "y_test = H.y_tst.astype(int)\n",
    "test_indices = np.random.choice(y_test.shape[0],test_size,replace=False)\n",
    "X_test_small = X_test[test_indices]\n",
    "y_test_small = y_test[test_indices]#\n",
    "lab_size = 20\n",
    "Ds = H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = M.X_train\n",
    "X_test = M.X_test\n",
    "y_train = M.y_train.astype(int)\n",
    "y_test = M.y_test.astype(int)\n",
    "test_indices = np.random.choice(y_test.shape[0],test_size,replace=False)\n",
    "X_test_small = X_test[test_indices]\n",
    "y_test_small = y_test[test_indices]#\n",
    "lab_size = 20\n",
    "Ds = M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = A.train_data.numpy()\n",
    "m,s = X_train.mean(0),X_train.std(0)\n",
    "X_test = At.test_data.numpy()#[:test_size]\n",
    "y_train = A.train_labels.numpy().astype(int)\n",
    "y_test = At.test_labels.numpy().astype(int)\n",
    "test_indices = np.random.choice(y_test.shape[0],test_size,replace=False)\n",
    "X_train = (X_train-m)/s\n",
    "X_test = (X_test-m)/s\n",
    "X_test_small = X_test[test_indices]\n",
    "y_test_small = y_test[test_indices]#\n",
    "\n",
    "lab_size = 200\n",
    "Ds = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Ya.X_train\n",
    "m,s = X_train.mean(0),X_train.std(0)\n",
    "X_test = Ya.X_test\n",
    "y_train = Ya.y_train.astype(int)\n",
    "y_test = Ya.y_test.astype(int)\n",
    "test_indices = np.random.choice(y_test.shape[0],test_size,replace=False)\n",
    "X_train = (X_train-m)/s\n",
    "X_test = (X_test-m)/s\n",
    "X_test_small = X_test[test_indices]\n",
    "y_test_small = y_test[test_indices]#\n",
    "\n",
    "lab_size = 800\n",
    "Ds = Ya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with FixedNumpySeed(0):\n",
    "    datasets = split_dataset(Ds,splits={'train':lab_size,'val':5000})\n",
    "\n",
    "X_lab = np.stack([datasets['train'][i][0] for i in range(len(datasets['train']))],axis=0)\n",
    "y_lab = np.stack([datasets['train'][i][1] for i in range(len(datasets['train']))],axis=0)\n",
    "X_dev = np.stack([datasets['val'][i][0] for i in range(len(datasets['val']))],axis=0)\n",
    "y_dev = np.stack([datasets['val'][i][1] for i in range(len(datasets['val']))],axis=0)\n",
    "X_unlab = np.stack([Ds[i][0] for i in range(len(Ds))],axis=0)\n",
    "y_unlab = np.stack([Ds[i][1] for i in range(len(Ds))],axis=0)\n",
    "#     labIndices, devIndices = classBalancedSampleIndices(Ds, lab_size+5000, 5000)\n",
    "#     unlab_indices = np.random.choice(y_train.shape[0],unlab_size,replace=False)\n",
    "# X_lab, X_dev = X_train[labIndices], X_train[devIndices]\n",
    "# y_lab, y_dev = y_train[labIndices], y_train[devIndices]\n",
    "# X_unlab = X_train[unlab_indices]\n",
    "# y_unlab = y_train[unlab_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7897260273972603"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_lab, y_lab)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best of 0.35486842105263156 with gamma=10, reg=0.5\n"
     ]
    }
   ],
   "source": [
    "unlab_indices = np.random.choice(X_unlab.shape[0],1000,replace=False)\n",
    "y_unlaba = y_unlab[unlab_indices]\n",
    "X_unlaba = X_unlab[unlab_indices]\n",
    "Y = np.concatenate((y_lab,y_unlaba))\n",
    "Y[len(y_lab):] =-1\n",
    "dev_accs = []\n",
    "hypers = []\n",
    "for gamma in [2,4,8,10]:\n",
    "    for reg in [1/16,1/8,1/4,1/2]:\n",
    "        graphssl = GraphSSL(reg=reg,gamma=gamma)\n",
    "        graphssl.fit(np.concatenate((X_lab,X_unlaba)), Y)\n",
    "        dev_accs.append(graphssl.score(X_dev,y_dev))\n",
    "        hypers.append((gamma,reg))\n",
    "best_gamma,best_reg = hypers[np.argmax(dev_accs)]\n",
    "graphssl = GraphSSL(reg=best_reg,gamma=best_gamma)\n",
    "graphssl.fit(np.concatenate((X_lab,X_unlaba)), Y)\n",
    "test_acc = graphssl.score(X_test,y_test)\n",
    "print(f\"Best of {test_acc} with gamma={best_gamma}, reg={best_reg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers[np.argmax(dev_accs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7936986301369863\n"
     ]
    }
   ],
   "source": [
    "unlab_indices = np.random.choice(X_unlab.shape[0],5000,replace=False)\n",
    "y_unlaba = y_unlab[unlab_indices]\n",
    "X_unlaba = X_unlab[unlab_indices]\n",
    "Y = np.concatenate((y_lab,y_unlaba))\n",
    "Y[len(y_lab):] =-1\n",
    "graphssl = GraphSSL(reg=.5,gamma=4)\n",
    "#print(\"constructed\")\n",
    "graphssl.fit(np.concatenate((X_lab,X_unlaba)), Y)\n",
    "print(graphssl.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1-graphssl.predict(X_test_small)==y_test_small).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_lab,X_unlab,X_test_small))\n",
    "# l = np.arange(200)\n",
    "# u = np.arange(200,1200)\n",
    "l = np.arange(X.shape[0])<lab_size\n",
    "u = (~l)&(np.arange(X.shape[0])<lab_size+X_unlab.shape[0])\n",
    "t = np.arange(X.shape[0])>=lab_size+X_unlab.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=1/2\n",
    "gamma=4\n",
    "#dists = np.sum((X[:,None,:]-X[None,:,:])**2,axis=-1)/s**2\n",
    "nx = np.linalg.norm(X,axis=1)\n",
    "dists = 1-(X@X.T)/(nx[:,None]*nx[None,:])\n",
    "W = np.exp(-dists*gamma)#-dists*100\n",
    "W -= np.diag(np.diag(W))\n",
    "#W += .00001*np.eye(X.shape[0])\n",
    "D = np.diag(np.sum(W,axis=-1))\n",
    "dm2 = np.sum(W,axis=-1)**-.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L =dm2[:,None]*(D-s*W)*dm2[None,:]\n",
    "Y = np.zeros((X.shape[0],Ds.num_classes))\n",
    "Y[:len(y_lab)] = oh(y_lab,Ds.num_classes)\n",
    "Ys = np.linalg.solve(L,Y)\n",
    "(Ys[t].argmax(-1)==y_test_small).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fu = -np.linalg.solve(L[u|t][:,u|t],(L[u|t][:,l]@oh(y_lab,Ds.num_classes)))\n",
    "(fu[-X_test_small.shape[0]:].argmax(-1)==y_test_small).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast kNN Ball Tree & Sparse Label Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "def normalize(X):\n",
    "    return X/np.linalg.norm(X,axis=1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=5\n",
    "# tree = sklearn.neighbors.BallTree(lab_and_unlab)\n",
    "# dists, indices = tree.query(lab_and_unlab,k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test acc of 0.1978 with k=19\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "kvals = list(range(1,20))\n",
    "for k in kvals:\n",
    "    knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(normalize(X_lab),y_lab)\n",
    "    scores.append(knn.score(normalize(X_dev), y_dev))\n",
    "\n",
    "best_k = kvals[np.argmax(scores)]\n",
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn.fit(normalize(X_lab),y_lab)\n",
    "test_acc = knn.score(normalize(X_test), y_test)\n",
    "print(f\"Best test acc of {test_acc} with k={best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.semi_supervised\n",
    "k=3\n",
    "# partially_labels = np.concatenate((y_lab,y_unlab))\n",
    "# partially_labels[len(y_lab):] =-1\n",
    "# LP = sklearn.semi_supervised.LabelPropagation(kernel='knn',gamma=gamma,n_neighbors=k)\n",
    "# LP.fit(normalize(lab_and_unlab),partially_labels)\n",
    "# LP.score(normalize(X_dev),y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marc_f/anaconda3/envs/default/lib/python3.6/site-packages/sklearn/semi_supervised/label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.label_distributions_ /= normalizer\n",
      "/home/marc_f/anaconda3/envs/default/lib/python3.6/site-packages/sklearn/semi_supervised/label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.label_distributions_ /= normalizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best of 0.6552054794520548 with alpha=0.1, k=16\n"
     ]
    }
   ],
   "source": [
    "unlab_indices = np.random.choice(X_unlab.shape[0],10000,replace=False)\n",
    "y_unlaba = y_unlab[unlab_indices]\n",
    "X_unlaba = X_unlab[unlab_indices]\n",
    "Y = np.concatenate((y_lab,y_unlaba))\n",
    "lab_and_unlab = np.concatenate((X_lab,X_unlaba))\n",
    "partially_labels = np.concatenate((y_lab,y_unlaba))\n",
    "partially_labels[len(y_lab):] =-1\n",
    "dev_accs = []\n",
    "hypers = []\n",
    "for alpha in [.1]:#,.3,.5]:\n",
    "    for k in [16]:#,24]:\n",
    "        label_prop_model = sklearn.semi_supervised.LabelSpreading(kernel = 'knn',\n",
    "                                                                  alpha=alpha,n_neighbors=k)\n",
    "        label_prop_model.fit(normalize(lab_and_unlab), partially_labels)\n",
    "        dev_accs.append(label_prop_model.score(normalize(X_dev),y_dev))\n",
    "        hypers.append((alpha,k))\n",
    "best_alpha,best_k = hypers[np.argmax(dev_accs)]\n",
    "label_prop_model = sklearn.semi_supervised.LabelSpreading(kernel = 'knn',\n",
    "                                        alpha=best_alpha,n_neighbors=best_k)\n",
    "label_prop_model.fit(normalize(lab_and_unlab), partially_labels)\n",
    "test_acc = label_prop_model.score(normalize(X_test),y_test)\n",
    "print(f\"Best of {test_acc} with alpha={best_alpha}, k={best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marc_f/anaconda3/envs/default/lib/python3.6/site-packages/sklearn/semi_supervised/label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.label_distributions_ /= normalizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best of 0.6412328767123288 with alpha=0.1, k=16\n"
     ]
    }
   ],
   "source": [
    "lab_and_unlab = np.concatenate((X_lab,X_unlaba))\n",
    "partially_labels = np.concatenate((y_lab,y_unlaba))\n",
    "partially_labels[len(y_lab):] =-1\n",
    "best_alpha,best_k = hypers[np.argmax(dev_accs)]\n",
    "label_prop_model = sklearn.semi_supervised.LabelSpreading(kernel = 'knn',\n",
    "                                        alpha=.1,n_neighbors=24)\n",
    "label_prop_model.fit(normalize(lab_and_unlab), partially_labels)\n",
    "test_acc = label_prop_model.score(normalize(X_test),y_test)\n",
    "print(f\"Best of {test_acc} with alpha={best_alpha}, k={best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(10),[(partially_labels==i).sum() for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_lab,X_unlab))\n",
    "nx = np.linalg.norm(X,axis=1)\n",
    "dists = 1-(X@X.T)/(nx[:,None]*nx[None,:])\n",
    "W = np.exp(-dists*2)#-dists*100\n",
    "W -= np.diag(np.diag(W))\n",
    "#W += .00001*np.eye(X.shape[0])\n",
    "D = np.diag(np.sum(W,axis=-1))\n",
    "dm2 = np.sum(W,axis=-1)**-.5\n",
    "L =dm2[:,None]*(D-W)*dm2[None,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nxtest = np.linalg.norm(X_test_small,axis=1)\n",
    "dists = 1-(X@X_test_small.T)/(nx[:,None]*nxtest[None,:])\n",
    "W2 = np.exp(-dists*2)#-dists*100\n",
    "#W += .00001*np.eye(X.shape[0])\n",
    "dm2_ = np.sum(W2,axis=0)**-.5\n",
    "L2 =dm2[:,None]*W2*dm2_[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.zeros((X.shape[0],Ds.num_classes))\n",
    "Y[:len(y_lab)] = oh(y_lab,Ds.num_classes)\n",
    "Ys = np.linalg.solve(L+np.eye(X.shape[0]),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((L2.T@graphssl.Ys).argmax(-1)==y_test_small).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_lab, y_lab)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ik(X1,X2):\n",
    "    X1n = X1/np.linalg.norm(X1,axis=1)[:,None]\n",
    "    X2n = X2/np.linalg.norm(X2,axis=1)[:,None]\n",
    "    return np.exp(-2*(1-X1n@X2n.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "\n",
    "partially_labels = np.concatenate((y_lab,y_unlab))\n",
    "partially_labels[len(y_lab):] =-1\n",
    "label_prop_model = LabelSpreading(kernel = ik,alpha=.0001)\n",
    "label_prop_model.fit(np.concatenate((X_lab,X_unlab)), partially_labels)\n",
    "label_prop_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oil.model_trainers.graphssl import GraphSSL\n",
    "graphssl = GraphSSL()\n",
    "graphssl.fit(np.concatenate((X_lab,X_unlab)), partially_labels)\n",
    "graphssl.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fu[-X_test.shape[0]:].argmax(-1)==y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fu[-X_test.shape[0]:].argmax(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(u|t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fu[t].argmax(-1)==y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "+0*np.eye(X.shape[0]-lab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.linalg.solve(X[l].T@X[l]+100*np.eye(X.shape[1]),X[l].T@oh(y_lab,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((X[l]@beta).argmax(-1)==y_lab).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((X[u]@beta).argmax(-1)==y_unlab).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((((x_test-m)/s)@beta).argmax(-1)==y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
