{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "470dbd8c-a903-4620-a6b2-d9c1234f49cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from torchvision.datasets import SVHN, MNIST, FashionMNIST, CIFAR10, CelebA, Omniglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8842642-75ee-4aa7-9fb8-5fe64747d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ssl_cifar_data_loaders(\n",
    "        data_path,\n",
    "        label_path,\n",
    "        labeled_batch_size,\n",
    "        unlabeled_batch_size,\n",
    "        num_workers, \n",
    "        transform_train, \n",
    "        transform_test, \n",
    "        use_validation=True, \n",
    "        ):\n",
    "\n",
    "    if use_validation:\n",
    "        print(\"Using train + validation\")\n",
    "        train_dir = os.path.join(data_path, \"train\")\n",
    "        test_dir = os.path.join(data_path, \"val\")\n",
    "    else:\n",
    "        train_dir = os.path.join(data_path, \"train+val\")\n",
    "        test_dir = os.path.join(data_path, \"test\")\n",
    "    train_set = torchvision.datasets.ImageFolder(train_dir, transform_train)\n",
    "    test_set = torchvision.datasets.ImageFolder(test_dir, transform_test)\n",
    "\n",
    "    with open(label_path) as f:\n",
    "        labels = dict(line.split(' ') for line in f.read().splitlines())\n",
    "    labeled_idxs, unlabeled_idxs, num_classes = relabel_dataset(train_set, labels)\n",
    "    assert len(train_set.imgs) == len(labeled_idxs) + len(unlabeled_idxs)\n",
    "\n",
    "    print(\"Num classes\", num_classes)\n",
    "    print(\"Labeled data: \", len(labeled_idxs))\n",
    "    print(\"Unlabeled data:\", len(unlabeled_idxs))\n",
    "\n",
    "    batch_sampler = LabeledUnlabeledBatchSampler(\n",
    "            labeled_idxs, unlabeled_idxs, labeled_batch_size, unlabeled_batch_size)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_sampler=batch_sampler,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=labeled_batch_size+unlabeled_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2*num_workers,  # Needs images twice as fast\n",
    "            pin_memory=True,\n",
    "            drop_last=False)\n",
    "\n",
    "    return train_loader, test_loader, num_classes\n",
    "\n",
    "\n",
    "#PAVEL: relabels the dataset using the labels file.\n",
    "def relabel_dataset(dataset, labels):\n",
    "    num_classes = 0\n",
    "    unlabeled_idxs = []\n",
    "    for idx in range(len(dataset.imgs)):\n",
    "        path, _ = dataset.imgs[idx]\n",
    "        filename = os.path.basename(path)\n",
    "        if filename in labels:\n",
    "            label_idx = dataset.class_to_idx[labels[filename]]\n",
    "            if label_idx > num_classes:\n",
    "                num_classes = label_idx\n",
    "            dataset.imgs[idx] = path, label_idx\n",
    "            del labels[filename]\n",
    "        else:\n",
    "            dataset.imgs[idx] = path, NO_LABEL\n",
    "            unlabeled_idxs.append(idx)\n",
    "\n",
    "    num_classes += 1\n",
    "\n",
    "    if len(labels) != 0:\n",
    "        message = \"List of unlabeled contains {} unknown files: {}, ...\"\n",
    "        some_missing = ', '.join(list(labels.keys())[:5])\n",
    "        raise LookupError(message.format(len(labels), some_missing))\n",
    "\n",
    "    labeled_idxs = sorted(set(range(len(dataset.imgs))) - set(unlabeled_idxs))\n",
    "\n",
    "    return labeled_idxs, unlabeled_idxs, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b98d4a3-6ef7-4293-9342-6c8959cb6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledUnlabeledBatchSampler(Sampler):\n",
    "    \"\"\"Minibatch index sampler for labeled and unlabeled indices. \n",
    "\n",
    "    An epoch is one pass through the labeled indices.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            labeled_idx, \n",
    "            unlabeled_idx, \n",
    "            labeled_batch_size, \n",
    "            unlabeled_batch_size):\n",
    "\n",
    "        self.labeled_idx = labeled_idx\n",
    "        self.unlabeled_idx = unlabeled_idx\n",
    "        self.unlabeled_batch_size = unlabeled_batch_size\n",
    "        self.labeled_batch_size = labeled_batch_size\n",
    "\n",
    "        assert len(self.labeled_idx) >= self.labeled_batch_size > 0\n",
    "        assert len(self.unlabeled_idx) >= self.unlabeled_batch_size > 0\n",
    "\n",
    "    @property\n",
    "    def num_labeled(self):\n",
    "        return len(self.labeled_idx)\n",
    "\n",
    "    def __iter__(self):\n",
    "        print(\"Balle balle\")\n",
    "        labeled_iter = iterate_once(self.labeled_idx)\n",
    "        unlabeled_iter = iterate_eternally(self.unlabeled_idx)\n",
    "        return (\n",
    "            labeled_batch + unlabeled_batch\n",
    "            for (labeled_batch, unlabeled_batch)\n",
    "            in  zip(batch_iterator(labeled_iter, self.labeled_batch_size),\n",
    "                    batch_iterator(unlabeled_iter, self.unlabeled_batch_size))\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labeled_idx) // self.labeled_batch_size\n",
    "\n",
    "\n",
    "def iterate_once(iterable):\n",
    "    return np.random.permutation(iterable)\n",
    "\n",
    "\n",
    "def iterate_eternally(indices):\n",
    "    def infinite_shuffles():\n",
    "        while True:\n",
    "            yield np.random.permutation(indices)\n",
    "    return itertools.chain.from_iterable(infinite_shuffles())\n",
    "\n",
    "\n",
    "def batch_iterator(iterable, n):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip(*args)\n",
    "\n",
    "\n",
    "class TransformTwice:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, inp):\n",
    "        out1 = self.transform(inp)\n",
    "        out2 = self.transform(inp)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "675f0b14-53cf-48de-a528-667554fdd83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes 10\n",
      "Labeled data:  1000\n",
      "Unlabeled data: 49000\n"
     ]
    }
   ],
   "source": [
    "NO_LABEL = -1\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "        # transforms.RandomCrop(32, padding=4),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_train = TransformTwice(transform_train)\n",
    "\n",
    "trainloader, testloader, _ = make_ssl_cifar_data_loaders(\n",
    "    data_path='/scratch/rm5708/ml/ML_Project/flowgmm-public/data/images/cifar/cifar10/by-image/',\n",
    "    label_path='/scratch/rm5708/ml/ML_Project/flowgmm-public/data/labels/cifar10/1000_balanced_labels/00.txt',\n",
    "    labeled_batch_size=32,\n",
    "    unlabeled_batch_size=32,\n",
    "    num_workers=2, \n",
    "    transform_train=transform_train, \n",
    "    transform_test=transform_test, \n",
    "    use_validation=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba10beaa-b215-470a-b148-7eba29a16bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balle balle\n",
      "Balle balle\n"
     ]
    }
   ],
   "source": [
    "s = iter(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b2fa0c4-26b9-4ade-969f-1a214cc9a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = next(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a2665ff-f261-4173-83f4-5c10987856c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balle balle\n",
      "Balle balle\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for ((x1, x2), y) in trainloader:\n",
    "    print(x1.shape)\n",
    "    print(x2.shape)\n",
    "    print(y.shape)\n",
    "    print((x1 == x2).all())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e09b5c8-0f1c-4d6e-aee4-09cb89e53d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.ImageFolder('/scratch/rm5708/ml/ML_Project/flowgmm-public/data/images/cifar/cifar10/by-image/', transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a127733d-23ea-4306-b245-f76bc74b84dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, config: dict):\n",
    "        self.data_keys = set(['mnist', 'fashionmnist', 'cifar', 'svhn'])\n",
    "        self.config = config\n",
    "        self.labeled_ids = []\n",
    "        self.unlabeled_ids = []\n",
    "        self.image_tensors = []\n",
    "        self.labels = []\n",
    "    \n",
    "    def prepare(self, in_data='mnist', indata_size=5000, outdata_size=1700, label_ratio=0.1):\n",
    "        print(self.data_keys)\n",
    "        self.data_keys.remove(in_data)\n",
    "        # Prepare OOD data\n",
    "        for k in self.data_keys:\n",
    "            dataset = config[k]['dataset']\n",
    "            transforms = config[k]['transforms']\n",
    "            start_id = len(self.labels)\n",
    "            end_id = start_id + int(label_ratio * outdata_size)\n",
    "            for i, (img, _) in enumerate(dataset):\n",
    "                if i == outdata_size:\n",
    "                    break\n",
    "                img_tensor = transforms(img)\n",
    "                self.image_tensors.append(img_tensor)\n",
    "            self.labels += [0] * (int(label_ratio * outdata_size))\n",
    "            self.labels += [-1] * (int((1 - label_ratio) * outdata_size))\n",
    "            self.labeled_ids += range(start_id, end_id)\n",
    "            self.unlabeled_ids += range(end_id, len(self.labels))\n",
    "        \n",
    "        # Prepare ID data\n",
    "        dataset = config[in_data]['dataset']\n",
    "        transforms = config[in_data]['transforms']\n",
    "        start_id = len(self.labels)\n",
    "        end_id = start_id + int(label_ratio * indata_size)\n",
    "        for i, (img, _) in enumerate(dataset):\n",
    "            if i == indata_size:\n",
    "                break\n",
    "            img_tensor = transforms(img)\n",
    "            self.image_tensors.append(img_tensor)\n",
    "        self.labels += [1] * (int(label_ratio * indata_size))\n",
    "        self.labels += [-1] * (int((1 - label_ratio) * indata_size))\n",
    "        self.labeled_ids += range(start_id, end_id)\n",
    "        self.unlabeled_ids += range(end_id, len(self.labels))\n",
    "        \n",
    "        random.shuffle(self.labeled_ids)\n",
    "        random.shuffle(self.unlabeled_ids)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_tensors)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.image_tensors[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46127dc7-37fa-40b2-b30b-a9b257fcd3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/scratch/rm5708/ml/ML_Project/\"\n",
    "\n",
    "data_dir = os.path.join(root, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06341a58-c18b-4f13-9685-318212df2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = MNIST(root=data_dir, train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46a18199-f21c-4dca-8a0f-ca88fc3221c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_ids = np.random.randint(1000, size=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b77ff5d8-5187-4933-8290-988a0a69efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_labeled_ids = np.random.choice(mnist_ids, int(1000 * 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6130012-9fba-4906-8dbb-4cc0922751e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmnist_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmnist_labeled_ids\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/full_time/lib/python3.8/site-packages/torchvision/datasets/mnist.py:138\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16fcd9e-3982-4eb7-9296-cd7895cd94c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
