{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ed8347a9-f7a4-48f0-a865-46a7c433c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8a736c-f24f-4aec-8fba-c7495dc0b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/scratch/rm5708/ml/ML_Project/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc182a2-8229-4577-a14e-bdc03c319fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(root, 'flowgmm-public'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "076dcdf3-13ad-4440-9baa-50095c92129f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/envs/full_time/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import flow_ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c4640cb-7449-43e0-a370-8feaf2e65e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo\n"
     ]
    }
   ],
   "source": [
    "print(\"yolo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1216aac-ea5a-4df5-be24-acf78a446b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import SVHN, MNIST, FashionMNIST, CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168123ec-107e-42e2-82b3-e22ae408ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(root, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff494df0-5a54-45ae-956a-5fec2b26f1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /scratch/rm5708/ml/ML_Project/data/train_32x32.mat\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "svhn_dataset = SVHN(root=data_dir, split='train', download=True)\n",
    "mnist_dataset = MNIST(root=data_dir, download=True)\n",
    "fashionmnist_dataset = FashionMNIST(root=data_dir, download=True)\n",
    "cifar_dataset = CIFAR10(root=data_dir, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2e8d1ce8-6872-4e6e-bfd8-2531f88343d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, config: dict):\n",
    "        self.data_keys = set(['mnist', 'fashionmnist', 'cifar', 'svhn'])\n",
    "        self.config = config\n",
    "        self.labeled_ids = []\n",
    "        self.unlabeled_ids = []\n",
    "        self.image_tensors = []\n",
    "        self.labels = []\n",
    "    \n",
    "    def prepare(self, in_data='mnist', indata_size=5000, outdata_size=1700, label_ratio=0.1):\n",
    "        print(self.data_keys)\n",
    "        self.data_keys.remove(in_data)\n",
    "        # Prepare OOD data\n",
    "        for k in self.data_keys:\n",
    "            dataset = config[k]['dataset']\n",
    "            transforms = config[k]['transforms']\n",
    "            start_id = len(self.labels)\n",
    "            end_id = start_id + int(label_ratio * outdata_size)\n",
    "            for i, (img, _) in enumerate(dataset):\n",
    "                if i == outdata_size:\n",
    "                    break\n",
    "                img_tensor = transforms(img)\n",
    "                self.image_tensors.append(img_tensor)\n",
    "            self.labels += [0] * (int(label_ratio * outdata_size))\n",
    "            self.labels += [-1] * (int((1 - label_ratio) * outdata_size))\n",
    "            self.labeled_ids += range(start_id, end_id)\n",
    "            self.unlabeled_ids += range(end_id, len(self.labels))\n",
    "        \n",
    "        # Prepare ID data\n",
    "        dataset = config[in_data]['dataset']\n",
    "        transforms = config[in_data]['transforms']\n",
    "        start_id = len(self.labels)\n",
    "        end_id = start_id + int(label_ratio * indata_size)\n",
    "        for i, (img, _) in enumerate(dataset):\n",
    "            if i == indata_size:\n",
    "                break\n",
    "            img_tensor = transforms(img)\n",
    "            self.image_tensors.append(img_tensor)\n",
    "        self.labels += [1] * (int(label_ratio * indata_size))\n",
    "        self.labels += [-1] * (int((1 - label_ratio) * indata_size))\n",
    "        self.labeled_ids += range(start_id, end_id)\n",
    "        self.unlabeled_ids += range(end_id, len(self.labels))\n",
    "        \n",
    "        random.shuffle(self.labeled_ids)\n",
    "        random.shuffle(self.unlabeled_ids)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_tensors)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        labeled_id = self.labeled_ids[idx % len(self.labeled_ids)]\n",
    "        unlabeled_id = self.unlabeled_ids[idx % len(self.unlabeled_ids)]\n",
    "        return self.image_tensors[labeled_id], self.image_tensors[unlabeled_id], self.labels[labeled_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "941c118c-c611-4633-a341-ec192018a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLDataset():\n",
    "    def __init__(self, config: dict):\n",
    "        self.data_keys = set(['mnist', 'fashionmnist', 'cifar', 'svhn'])\n",
    "        self.config = config\n",
    "        self.image_tensors = []\n",
    "        self.labels = []\n",
    "    \n",
    "    def prepare(self, in_data='mnist', indata_size=600, outdata_size=200):\n",
    "        print(self.data_keys)\n",
    "        self.data_keys.remove(in_data)\n",
    "        # Prepare OOD data\n",
    "        for k in self.data_keys:\n",
    "            dataset = config[k]['dataset']\n",
    "            transforms = config[k]['transforms']\n",
    "            for i, (img, _) in enumerate(dataset):\n",
    "                if i == outdata_size:\n",
    "                    break\n",
    "                img_tensor = transforms(img)\n",
    "                self.image_tensors.append(img_tensor)\n",
    "            self.labels += [0] * outdata_size\n",
    "        \n",
    "        # Prepare ID data\n",
    "        dataset = config[in_data]['dataset']\n",
    "        transforms = config[in_data]['transforms']\n",
    "        for i, (img, _) in enumerate(dataset):\n",
    "            if i == indata_size:\n",
    "                break\n",
    "            img_tensor = transforms(img)\n",
    "            self.image_tensors.append(img_tensor)\n",
    "        self.labels += [1] * indata_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_tensors)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.image_tensors[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "84b9a022-be6a-4b52-8ffb-a43303b35f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "svhn_transforms = transforms.Compose([\n",
    "                    transforms.Grayscale(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize((32,32))\n",
    "                ])\n",
    "\n",
    "mnist_transforms = transforms.Compose([\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Resize((32,32))\n",
    "                ])\n",
    "\n",
    "fashionmnist_transforms = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize((32,32))\n",
    "                ])\n",
    "\n",
    "cifar_transforms = transforms.Compose([\n",
    "                    transforms.Grayscale(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize((32,32))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f96446aa-9056-4afc-9d1a-e6a8af4eeb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config['svhn'] = {}\n",
    "config['svhn']['dataset'] = svhn_dataset\n",
    "config['svhn']['transforms'] = svhn_transforms\n",
    "\n",
    "config['mnist'] = {}\n",
    "config['mnist']['dataset'] = mnist_dataset\n",
    "config['mnist']['transforms'] = mnist_transforms\n",
    "\n",
    "config['fashionmnist'] = {}\n",
    "config['fashionmnist']['dataset'] = fashionmnist_dataset\n",
    "config['fashionmnist']['transforms'] = fashionmnist_transforms\n",
    "\n",
    "config['cifar'] = {}\n",
    "config['cifar']['dataset'] = cifar_dataset\n",
    "config['cifar']['transforms'] = cifar_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be1ffb39-b419-4c66-9100-0dfc81b4c611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cifar', 'mnist', 'svhn', 'fashionmnist'}\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset(config)\n",
    "ds.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8e6bcfaf-974b-4f0a-9b23-ddef934cad66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /scratch/rm5708/ml/ML_Project/data/test_32x32.mat\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "svhn_test_dataset = SVHN(root=data_dir, split='test', download=True)\n",
    "mnist_test_dataset = MNIST(root=data_dir, train=False, download=True)\n",
    "fashionmnist_test_dataset = FashionMNIST(root=data_dir, train=False, download=True)\n",
    "cifar_test_dataset = CIFAR10(root=data_dir, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c460804b-f229-49d3-b362-68948025a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = {}\n",
    "\n",
    "test_config['svhn'] = {}\n",
    "test_config['svhn']['dataset'] = svhn_test_dataset\n",
    "test_config['svhn']['transforms'] = svhn_transforms\n",
    "\n",
    "test_config['mnist'] = {}\n",
    "test_config['mnist']['dataset'] = mnist_test_dataset\n",
    "test_config['mnist']['transforms'] = mnist_transforms\n",
    "\n",
    "test_config['fashionmnist'] = {}\n",
    "test_config['fashionmnist']['dataset'] = fashionmnist_test_dataset\n",
    "test_config['fashionmnist']['transforms'] = fashionmnist_transforms\n",
    "\n",
    "test_config['cifar'] = {}\n",
    "test_config['cifar']['dataset'] = cifar_test_dataset\n",
    "test_config['cifar']['transforms'] = cifar_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "da501a38-eef3-4564-add8-434a2fdbc2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cifar', 'mnist', 'svhn', 'fashionmnist'}\n"
     ]
    }
   ],
   "source": [
    "test_ds = SLDataset(test_config)\n",
    "test_ds.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "da1d6d54-c15e-45ca-9bed-ef89a893325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledUnlabeledBatchSampler(Sampler):\n",
    "    \"\"\"Minibatch index sampler for labeled and unlabeled indices. \n",
    "\n",
    "    An epoch is one pass through the labeled indices.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            labeled_idx, \n",
    "            unlabeled_idx, \n",
    "            labeled_batch_size, \n",
    "            unlabeled_batch_size):\n",
    "\n",
    "        self.labeled_idx = labeled_idx\n",
    "        self.unlabeled_idx = unlabeled_idx\n",
    "        self.unlabeled_batch_size = unlabeled_batch_size\n",
    "        self.labeled_batch_size = labeled_batch_size\n",
    "\n",
    "        assert len(self.labeled_idx) >= self.labeled_batch_size > 0\n",
    "        assert len(self.unlabeled_idx) >= self.unlabeled_batch_size > 0\n",
    "\n",
    "    @property\n",
    "    def num_labeled(self):\n",
    "        return len(self.labeled_idx)\n",
    "\n",
    "    def __iter__(self):\n",
    "        labeled_iter = iterate_once(self.labeled_idx)\n",
    "        unlabeled_iter = iterate_eternally(self.unlabeled_idx)\n",
    "        return (\n",
    "            labeled_batch + unlabeled_batch\n",
    "            for (labeled_batch, unlabeled_batch)\n",
    "            in  zip(batch_iterator(labeled_iter, self.labeled_batch_size),\n",
    "                    batch_iterator(unlabeled_iter, self.unlabeled_batch_size))\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labeled_idx) // self.labeled_batch_size\n",
    "\n",
    "\n",
    "def iterate_once(iterable):\n",
    "    return np.random.permutation(iterable)\n",
    "\n",
    "\n",
    "def iterate_eternally(indices):\n",
    "    def infinite_shuffles():\n",
    "        while True:\n",
    "            yield np.random.permutation(indices)\n",
    "    return itertools.chain.from_iterable(infinite_shuffles())\n",
    "\n",
    "\n",
    "def batch_iterator(iterable, n):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3e9cfe1b-ef0d-4476-b809-1950aff62642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_batch_sampler = LabeledUnlabeledBatchSampler(ds.labeled_ids, ds.unlabeled_ids, 32, 32)\n",
    "# test_batch_sampler = LabeledUnlabeledBatchSampler(test_ds.labeled_ids, test_ds.unlabeled_ids, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d4e1596f-c240-4ca7-8b61-18d10f29909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainloader = torch.utils.data.DataLoader(ds, batch_size=64, shuffle=True, pin_memory=True)\n",
    "# testloader = torch.utils.data.DataLoader(test_ds, batch_size=64, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4630d7a2-7e5a-4a69-9da8-3d0c9bfb42c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainloader = torch.utils.data.DataLoader(ds, batch_sampler=train_batch_sampler, pin_memory=True)\n",
    "# testloader = torch.utils.data.DataLoader(test_ds, batch_sampler=test_batch_sampler, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2a8aea62-a23d-4b3c-8d6b-50f7a2f4b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_sampler = LabeledUnlabeledBatchSampler(ds.labeled_ids, ds.unlabeled_ids, 16, 16)\n",
    "trainloader = torch.utils.data.DataLoader(ds, batch_sampler=train_batch_sampler, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(test_ds, batch_size=32, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f553a657-6dc7-49ba-b50a-05ae687af69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "torch.Size([64, 1, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for batch in trainloader:\n",
    "    print(batch[0].get_device())\n",
    "    print(batch[1].shape)\n",
    "    print(batch[2].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "524191b2-a35e-48d9-aafa-9bed0e5f0f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "-1\n",
      "torch.Size([64, 1, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for batch in testloader:\n",
    "    print(len(batch))\n",
    "    print(batch[0].get_device())\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2124dd42-191d-454d-b2bb-51705c0466f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (1, 32, 32)\n",
    "flow = 'MNISTResidualFlow'\n",
    "model_cfg = getattr(flow_ssl, flow)\n",
    "net = model_cfg(in_channels=img_shape[0], num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "65002dfb-566c-4820-add7-8ffcf1bf0869",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flow in [\"iCNN3d\", \"iResnetProper\",\"SmallResidualFlow\",\"ResidualFlow\",\"MNISTResidualFlow\"]:\n",
    "    net = net.flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f5920588-44f1-46f1-90ce-575b5529cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.train_flows.utils import train_utils\n",
    "\n",
    "means = 'random'\n",
    "means_r = 1.0\n",
    "cov_std = 1.0\n",
    "img_shape = (1, 32, 32)\n",
    "device = 'cuda'\n",
    "n_classes = 2\n",
    "\n",
    "net = net.to(device)\n",
    "r = means_r\n",
    "cov_std = torch.ones((n_classes)) * cov_std\n",
    "cov_std = cov_std.to(device)\n",
    "means = train_utils.get_means(means, num_means=n_classes, r=means_r, trainloader=trainloader, \n",
    "                        shape=img_shape, device=device, net=net)\n",
    "means_init = means.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9487a807-bb50-4650-b26f-e294679e7af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: tensor([[ 0.6703,  0.0703, -0.0226,  ..., -0.4330, -0.0388, -0.3634],\n",
      "        [-0.1784,  0.8074, -0.1174,  ...,  0.0871, -0.4618, -0.2802]],\n",
      "       device='cuda:0')\n",
      "Cov std: tensor([1., 1.], device='cuda:0')\n",
      "Pairwise dists: [[ 0.         45.62108296]\n",
      " [45.62108296  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "print(\"Means:\", means)\n",
    "print(\"Cov std:\", cov_std)\n",
    "means_np = means.cpu().numpy()\n",
    "print(\"Pairwise dists:\", cdist(means_np, means_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dd372806-894b-4d04-bac1-9266b46015fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using learnable means\n"
     ]
    }
   ],
   "source": [
    "from flow_ssl.distributions import SSLGaussMixture\n",
    "from flow_ssl import FlowLoss\n",
    "\n",
    "means_trainable = True\n",
    "covs_trainable = True\n",
    "weights_trainable = True\n",
    "\n",
    "if means_trainable:\n",
    "    print(\"Using learnable means\")\n",
    "    means = torch.tensor(means_np, requires_grad=True, device=device)\n",
    "\n",
    "prior = SSLGaussMixture(means, device=device)\n",
    "prior.weights.requires_grad = weights_trainable\n",
    "prior.inv_cov_stds.requires_grad = covs_trainable\n",
    "loss_fn = FlowLoss(prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "416efc52-ebbf-4011-8055-15feb3e81734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.train_flows.utils import norm_util\n",
    "import torch.optim as optim\n",
    "\n",
    "param_groups = norm_util.get_param_groups(net, 0.0, norm_suffix='weight_g')\n",
    "\n",
    "optimizer = optim.Adam(param_groups, lr=1e-3)\n",
    "opt_gmm = optim.Adam([prior.means, prior.weights, prior.inv_cov_stds], lr=1e-4, weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "11c3f709-4854-4f51-95c1-9d0ab84a5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir='./')\n",
    "device = 'cuda' if torch.cuda.is_available() and len([0]) > 0 else 'cpu'\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "85e9c466-b4f6-4f86-a329-455280c72332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(epoch, net, testloader, device, loss_fn, writer=None, postfix=\"\",\n",
    "                    show_classification_images=False, confusion=False):\n",
    "    net.eval()\n",
    "    loss_meter = shell_util.AverageMeter()\n",
    "    jaclogdet_meter = shell_util.AverageMeter()\n",
    "    acc_meter = shell_util.AverageMeter()\n",
    "    all_pred_labels = []\n",
    "    all_xs = []\n",
    "    all_ys = []\n",
    "    all_zs = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(testloader.dataset)) as progress_bar:\n",
    "            for x, y in testloader:\n",
    "                all_xs.append(x.data.numpy())\n",
    "                all_ys.append(y.data.numpy())\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                z = net(x)\n",
    "                all_zs.append(z.cpu().data.numpy())\n",
    "                sldj = net.logdet()\n",
    "                loss = loss_fn(z, y=y, sldj=sldj)\n",
    "                loss_meter.update(loss.item(), x.size(0))\n",
    "                jaclogdet_meter.update(sldj.mean().item(), x.size(0))\n",
    "\n",
    "                preds = loss_fn.prior.classify(z.reshape((len(z), -1)))\n",
    "                preds = preds.reshape(y.shape)\n",
    "                all_pred_labels.append(preds.cpu().data.numpy())\n",
    "                acc = (preds == y).float().mean().item()\n",
    "                acc_meter.update(acc, x.size(0))\n",
    "\n",
    "                progress_bar.set_postfix(loss=loss_meter.avg,\n",
    "                                     bpd=optim_util.bits_per_dim(x, loss_meter.avg),\n",
    "                                     acc=acc_meter.avg)\n",
    "                progress_bar.update(x.size(0))\n",
    "    all_pred_labels = np.hstack(all_pred_labels)\n",
    "    all_xs = np.vstack(all_xs)\n",
    "    all_zs = np.vstack(all_zs)\n",
    "    all_ys = np.hstack(all_ys)\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.add_scalar(\"test/loss{}\".format(postfix), loss_meter.avg, epoch)\n",
    "        writer.add_scalar(\"test/acc{}\".format(postfix), acc_meter.avg, epoch)\n",
    "        writer.add_scalar(\"test/bpd{}\".format(postfix), optim_util.bits_per_dim(x, loss_meter.avg), epoch)\n",
    "        writer.add_scalar(\"test/jaclogdet{}\".format(postfix), jaclogdet_meter.avg, epoch)\n",
    "\n",
    "        for cls in range(np.max(all_pred_labels)+1):\n",
    "            num_imgs_cls = (all_pred_labels==cls).sum()\n",
    "            writer.add_scalar(\"test_clustering/num_class_{}_{}\".format(cls,postfix), \n",
    "                    num_imgs_cls, epoch)\n",
    "            if num_imgs_cls == 0:\n",
    "                writer.add_scalar(\"test_clustering/num_class_{}_{}\".format(cls,postfix), \n",
    "                    0., epoch)\n",
    "                continue\n",
    "            writer.add_histogram('label_distributions/num_class_{}_{}'.format(cls,postfix), \n",
    "                    all_ys[all_pred_labels==cls], epoch)\n",
    "\n",
    "            writer.add_histogram(\n",
    "                'distance_distributions/num_class_{}'.format(cls),\n",
    "                torch.norm(torch.tensor(all_zs[all_pred_labels==cls]) - loss_fn.prior.means[cls].cpu(), p=2, dim=1),\n",
    "                epoch\n",
    "            )\n",
    "\n",
    "            if show_classification_images:\n",
    "                images_cls = all_xs[all_pred_labels==cls][:10]\n",
    "                images_cls = torch.from_numpy(images_cls).float()\n",
    "                images_cls_concat = torchvision.utils.make_grid(\n",
    "                        images_cls, nrow=2, padding=2, pad_value=255)\n",
    "                writer.add_image(\"test_clustering/class_{}\".format(cls), \n",
    "                        images_cls_concat)\n",
    "\n",
    "        if confusion:\n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "            cm = confusion_matrix(all_ys, all_pred_labels)\n",
    "            cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "            sns.heatmap(cm, annot=True, cmap=plt.cm.Blues)\n",
    "            plt.ylabel('True label')\n",
    "            plt.xlabel('Predicted label')\n",
    "            conf_img = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
    "            conf_img = torch.tensor(conf_img.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
    "            writer.add_image(\"confusion\", conf_img, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c5aebe9b-7dd6-4e51-8ae8-24ce144978cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_labels = len(ds.labeled_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9e14cd2d-44e1-4f81-8ba5-b868870dc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(net, prior, batch_size, cls, device, sample_shape):\n",
    "    \"\"\"Sample from RealNVP model.\n",
    "    Args:\n",
    "        net (torch.nn.DataParallel): The RealNVP model wrapped in DataParallel.\n",
    "        batch_size (int): Number of samples to generate.\n",
    "        device (torch.device): Device to use.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        if cls is not None:\n",
    "            z = prior.sample((batch_size,), gaussian_id=cls)\n",
    "        else:\n",
    "            z = prior.sample((batch_size,))\n",
    "        x = net.inverse(z)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c129e139-d9c4-48b9-8d47-cd070b329153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.train_flows.utils import optim_util\n",
    "\n",
    "def train(epoch, net, trainloader, device, optimizer, opt_gmm, loss_fn,\n",
    "          label_weight, max_grad_norm, consistency_weight,\n",
    "          writer, use_unlab=True,  acc_train_all_labels=False,\n",
    "          ):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    loss_meter = shell_util.AverageMeter()\n",
    "    loss_unsup_meter = shell_util.AverageMeter()\n",
    "    loss_nll_meter = shell_util.AverageMeter()\n",
    "    loss_consistency_meter = shell_util.AverageMeter()\n",
    "    jaclogdet_meter = shell_util.AverageMeter()\n",
    "    acc_meter = shell_util.AverageMeter()\n",
    "    acc_all_meter = shell_util.AverageMeter()\n",
    "    with tqdm(total=2*total_labels) as progress_bar:\n",
    "        for x1, x2, y in trainloader:\n",
    "\n",
    "            x1 = x1.to(device)\n",
    "            if not acc_train_all_labels:\n",
    "                y = y.to(device)\n",
    "            else:\n",
    "                y, y_all_lab = y[:, 0], y[:, 1]\n",
    "                y = y.to(device)\n",
    "                y_all_lab = y_all_lab.to(device)\n",
    "\n",
    "            labeled_mask = (y != NO_LABEL)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            opt_gmm.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                x2 = x2.to(device)\n",
    "                # print(x2.get_device(), next(net.parameters()).is_cuda)\n",
    "                z2 = net(x2)\n",
    "                z2 = z2.detach()\n",
    "                pred2 = loss_fn.prior.classify(z2.reshape((len(z2), -1)))\n",
    "\n",
    "            z1 = net(x1)\n",
    "            sldj = net.logdet()\n",
    "\n",
    "            z_all = z1.reshape((len(z1), -1))\n",
    "            z_labeled = z_all[labeled_mask]\n",
    "            y_labeled = y[labeled_mask]\n",
    "\n",
    "            logits_all = loss_fn.prior.class_logits(z_all)\n",
    "            logits_labeled = logits_all[labeled_mask]\n",
    "            loss_nll = F.cross_entropy(logits_labeled, y_labeled)\n",
    "\n",
    "            if use_unlab:\n",
    "                loss_unsup = loss_fn(z1, sldj=sldj)\n",
    "                loss = loss_nll * label_weight + loss_unsup\n",
    "            else:\n",
    "                loss_unsup = torch.tensor([0.])\n",
    "                loss = loss_nll\n",
    "\n",
    "            # consistency loss\n",
    "            loss_consistency = loss_fn(z1, sldj=sldj, y=pred2)\n",
    "            loss = loss + loss_consistency * consistency_weight\n",
    "\n",
    "            loss.backward()\n",
    "            optim_util.clip_grad_norm(optimizer, max_grad_norm)\n",
    "            optimizer.step()\n",
    "            opt_gmm.step()\n",
    "\n",
    "            preds_all = torch.argmax(logits_all, dim=1)\n",
    "            preds = preds_all[labeled_mask]\n",
    "            acc = (preds == y_labeled).float().mean().item()\n",
    "            if acc_train_all_labels:\n",
    "                acc_all = (preds_all == y_all_lab).float().mean().item()\n",
    "            else:\n",
    "                acc_all = acc\n",
    "\n",
    "            acc_meter.update(acc, x1.size(0))\n",
    "            acc_all_meter.update(acc_all, x1.size(0))\n",
    "            loss_meter.update(loss.item(), x1.size(0))\n",
    "            loss_unsup_meter.update(loss_unsup.item(), x1.size(0))\n",
    "            loss_nll_meter.update(loss_nll.item(), x1.size(0))\n",
    "            jaclogdet_meter.update(sldj.mean().item(), x1.size(0))\n",
    "            loss_consistency_meter.update(loss_consistency.item(), x1.size(0))\n",
    "\n",
    "            progress_bar.set_postfix(loss=loss_meter.avg,\n",
    "                                     bpd=optim_util.bits_per_dim(x1, loss_unsup_meter.avg),\n",
    "                                     acc=acc_meter.avg,\n",
    "                                     acc_all=acc_all_meter.avg)\n",
    "            progress_bar.update(y_labeled.size(0))\n",
    "\n",
    "    x1_img = torchvision.utils.make_grid(x1[:10], nrow=2 , padding=2, pad_value=255)\n",
    "    x2_img = torchvision.utils.make_grid(x2[:10], nrow=2 , padding=2, pad_value=255)\n",
    "    writer.add_image(\"data/x1\", x1_img)\n",
    "    writer.add_image(\"data/x2\", x2_img)\n",
    "\n",
    "    writer.add_scalar(\"train/loss\", loss_meter.avg, epoch)\n",
    "    writer.add_scalar(\"train/loss_unsup\", loss_unsup_meter.avg, epoch)\n",
    "    writer.add_scalar(\"train/loss_nll\", loss_nll_meter.avg, epoch)\n",
    "    writer.add_scalar(\"train/jaclogdet\", jaclogdet_meter.avg, epoch)\n",
    "    writer.add_scalar(\"train/acc\", acc_meter.avg, epoch)\n",
    "    writer.add_scalar(\"train/acc_all\", acc_all_meter.avg, epoch)\n",
    "    writer.add_scalar(\"train/bpd\", optim_util.bits_per_dim(x1, loss_unsup_meter.avg), epoch)\n",
    "    writer.add_scalar(\"train/loss_consistency\", loss_consistency_meter.avg, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb4663-d856-41b4-8e60-b657bba607bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018636226654052734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 43,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2020,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10fc71621ec4780943b6147ef2fd992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n",
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012607574462890625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 43,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1200,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d376dd1324494e44bf29974e63fc34fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-27614823/ipykernel_1695847/1258797901.py:78: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  conf_img = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
      "/state/partition1/job-27614823/ipykernel_1695847/1258797901.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  conf_img = torch.tensor(conf_img.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
      "/state/partition1/job-27614823/ipykernel_1695847/3247889665.py:74: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  img_data = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
      "/state/partition1/job-27614823/ipykernel_1695847/3247889665.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_data = torch.tensor(img_data.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
      "/state/partition1/job-27614823/ipykernel_1695847/3247889665.py:79: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  writer.add_scalar(\"train_gmm/weight/{}\".format(i), F.softmax(prior.weights)[i], epoch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012813806533813477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 43,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2020,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fd5a3dca464f4fa4ec655535ed8cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n",
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012205123901367188,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 43,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1200,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3a68aa00ca4194924e61a89569e101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-27614823/ipykernel_1695847/1258797901.py:78: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  conf_img = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
      "/state/partition1/job-27614823/ipykernel_1695847/1258797901.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  conf_img = torch.tensor(conf_img.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
      "/state/partition1/job-27614823/ipykernel_1695847/3247889665.py:74: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  img_data = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
      "/state/partition1/job-27614823/ipykernel_1695847/3247889665.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_data = torch.tensor(img_data.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
      "/state/partition1/job-27614823/ipykernel_1695847/3247889665.py:79: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  writer.add_scalar(\"train_gmm/weight/{}\".format(i), F.softmax(prior.weights)[i], epoch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012593984603881836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 43,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2020,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aed39daa4114be590eb5e7f49d56d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n",
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01257014274597168,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 43,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1200,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01571e2a93a343898989a7d741aac7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-27614823/ipykernel_1695847/1258797901.py:78: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  conf_img = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
      "/state/partition1/job-27614823/ipykernel_1695847/1258797901.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  conf_img = torch.tensor(conf_img.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
      "/state/partition1/job-27614823/ipykernel_1695847/3247889665.py:74: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  img_data = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
      "/state/partition1/job-27614823/ipykernel_1695847/3247889665.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_data = torch.tensor(img_data.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
      "/state/partition1/job-27614823/ipykernel_1695847/3247889665.py:79: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  writer.add_scalar(\"train_gmm/weight/{}\".format(i), F.softmax(prior.weights)[i], epoch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01171112060546875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 43,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2020,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7691f6304e79458f838bb9867be275b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n",
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n"
     ]
    }
   ],
   "source": [
    "from experiments.train_flows.utils import shell_util\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "NO_LABEL = -1\n",
    "schedule = None\n",
    "n_epochs = 10\n",
    "lr = 5e-4\n",
    "lr_gmm = 1e-4\n",
    "consistency_weight = 1.0\n",
    "consistency_rampup = 1\n",
    "label_weight = 1.0\n",
    "max_grad_norm = 100.0\n",
    "save_freq = 2\n",
    "ckptdir = './'\n",
    "eval_freq = 1\n",
    "confusion = True\n",
    "num_samples = 50\n",
    "\n",
    "def linear_rampup(final_value, epoch, num_epochs, start_epoch=0):\n",
    "    t = (epoch - start_epoch + 1) / num_epochs\n",
    "    if t > 1:\n",
    "        t = 1.\n",
    "    return t * final_value\n",
    "\n",
    "for epoch in range(start_epoch, n_epochs):\n",
    "    cons_weight = linear_rampup(consistency_weight, epoch, consistency_rampup, start_epoch)\n",
    "    \n",
    "    writer.add_scalar(\"hypers/learning_rate\", lr, epoch)\n",
    "    writer.add_scalar(\"hypers/learning_rate_gmm\", lr_gmm, epoch)\n",
    "    writer.add_scalar(\"hypers/consistency_weight\", cons_weight, epoch)\n",
    "\n",
    "    train(epoch, net, trainloader, device, optimizer, opt_gmm, loss_fn,\n",
    "          label_weight, max_grad_norm, cons_weight,\n",
    "          writer, use_unlab=True)\n",
    "\n",
    "    # Save checkpoint\n",
    "    if (epoch % save_freq == 0):\n",
    "        print('Saving...')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'means': prior.means,\n",
    "        }\n",
    "        os.makedirs(ckptdir, exist_ok=True)\n",
    "        torch.save(state, os.path.join(ckptdir, str(epoch)+'.pt'))\n",
    "\n",
    "    # Save samples and data\n",
    "    if epoch % eval_freq == 0:\n",
    "        test_classifier(epoch, net, testloader, device, loss_fn, writer, confusion=confusion)\n",
    "        # if args.swa:\n",
    "        #     optimizer.swap_swa_sgd() \n",
    "        #     print(\"updating bn\")\n",
    "        #     SWA.bn_update(bn_loader, net)\n",
    "        #     utils.test_classifier(epoch, net, testloader, device, loss_fn, \n",
    "        #             writer, postfix=\"_swa\")\n",
    "\n",
    "        z_means = prior.means\n",
    "        data_means = net.inverse(z_means)\n",
    "        z_mean_imgs = torchvision.utils.make_grid(\n",
    "                z_means.reshape((n_classes, *img_shape)), nrow=2)\n",
    "        data_mean_imgs = torchvision.utils.make_grid(\n",
    "                data_means.reshape((n_classes, *img_shape)), nrow=2)\n",
    "        writer.add_image(\"z_means\", z_mean_imgs, epoch)\n",
    "        writer.add_image(\"data_means\", data_mean_imgs, epoch)\n",
    "\n",
    "        means_np = prior.means.detach().cpu().numpy()\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cdist(means_np, means_np))\n",
    "        img_data = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
    "        img_data = torch.tensor(img_data.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
    "        writer.add_image(\"mean_dists\", img_data, epoch)\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            writer.add_scalar(\"train_gmm/weight/{}\".format(i), F.softmax(prior.weights)[i], epoch)\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            writer.add_scalar(\"train_gmm/cov/{}\".format(i), F.softplus(prior.inv_cov_stds[i])**2, epoch)\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            writer.add_scalar(\"train_gmm/mean_dist_init/{}\".format(i), torch.norm(prior.means[i]-means_init[i], 2), epoch)\n",
    "\n",
    "        images = []\n",
    "        for i in range(n_classes):\n",
    "            images_cls = sample(net, loss_fn.prior, num_samples // n_classes,\n",
    "                                      cls=i, device=device, sample_shape=img_shape)\n",
    "            images.append(images_cls)\n",
    "            images_cls_concat = torchvision.utils.make_grid(\n",
    "                    images_cls, nrow=2, padding=2, pad_value=255)\n",
    "            writer.add_image(\"samples/class_\"+str(i), images_cls_concat)\n",
    "        images = torch.cat(images)\n",
    "        os.makedirs(os.path.join(ckptdir, 'samples'), exist_ok=True)\n",
    "        images_concat = torchvision.utils.make_grid(images, nrow=num_samples //  n_classes , padding=2, pad_value=255)\n",
    "        os.makedirs(ckptdir, exist_ok=True)\n",
    "        torchvision.utils.save_image(images_concat, \n",
    "                                    os.path.join(ckptdir, 'samples/epoch_{}.png'.format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17aae14-9f2f-4f72-a39f-1e6c61f9369e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
