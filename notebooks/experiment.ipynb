{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed8347a9-f7a4-48f0-a865-46a7c433c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from torchvision.datasets import SVHN, MNIST, FashionMNIST, CIFAR10, CelebA, Omniglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8a736c-f24f-4aec-8fba-c7495dc0b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/scratch/rm5708/ml/ML_Project/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc182a2-8229-4577-a14e-bdc03c319fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(root, 'flowgmm-public'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "076dcdf3-13ad-4440-9baa-50095c92129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flow_ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c4640cb-7449-43e0-a370-8feaf2e65e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo\n"
     ]
    }
   ],
   "source": [
    "print(\"yolo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1216aac-ea5a-4df5-be24-acf78a446b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import SVHN, MNIST, FashionMNIST, CIFAR10, CelebA, Omniglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168123ec-107e-42e2-82b3-e22ae408ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(root, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff494df0-5a54-45ae-956a-5fec2b26f1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /scratch/rm5708/ml/ML_Project/data/train_32x32.mat\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "svhn_dataset = SVHN(root=data_dir, split='train', download=True)\n",
    "mnist_dataset = MNIST(root=data_dir, download=True)\n",
    "fashionmnist_dataset = FashionMNIST(root=data_dir, download=True)\n",
    "cifar_dataset = CIFAR10(root=data_dir, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "223f31a9-c136-4c40-bc55-220717c451ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledUnlabeledBatchSampler(Sampler):\n",
    "    \"\"\"Minibatch index sampler for labeled and unlabeled indices. \n",
    "\n",
    "    An epoch is one pass through the labeled indices.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            labeled_idx, \n",
    "            unlabeled_idx, \n",
    "            labeled_batch_size, \n",
    "            unlabeled_batch_size):\n",
    "\n",
    "        self.labeled_idx = labeled_idx\n",
    "        self.unlabeled_idx = unlabeled_idx\n",
    "        self.unlabeled_batch_size = unlabeled_batch_size\n",
    "        self.labeled_batch_size = labeled_batch_size\n",
    "\n",
    "        assert len(self.labeled_idx) >= self.labeled_batch_size > 0\n",
    "        assert len(self.unlabeled_idx) >= self.unlabeled_batch_size > 0\n",
    "\n",
    "    @property\n",
    "    def num_labeled(self):\n",
    "        return len(self.labeled_idx)\n",
    "\n",
    "    def __iter__(self):\n",
    "        # print(\"Balle balle\")\n",
    "        labeled_iter = iterate_once(self.labeled_idx)\n",
    "        unlabeled_iter = iterate_eternally(self.unlabeled_idx)\n",
    "        return (\n",
    "            labeled_batch + unlabeled_batch\n",
    "            for (labeled_batch, unlabeled_batch)\n",
    "            in  zip(batch_iterator(labeled_iter, self.labeled_batch_size),\n",
    "                    batch_iterator(unlabeled_iter, self.unlabeled_batch_size))\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labeled_idx) // self.labeled_batch_size\n",
    "\n",
    "\n",
    "def iterate_once(iterable):\n",
    "    return np.random.permutation(iterable)\n",
    "\n",
    "\n",
    "def iterate_eternally(indices):\n",
    "    def infinite_shuffles():\n",
    "        while True:\n",
    "            yield np.random.permutation(indices)\n",
    "    return itertools.chain.from_iterable(infinite_shuffles())\n",
    "\n",
    "\n",
    "def batch_iterator(iterable, n):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip(*args)\n",
    "\n",
    "\n",
    "class TransformTwice:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, inp):\n",
    "        out1 = self.transform(inp)\n",
    "        out2 = self.transform(inp)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2e8d1ce8-6872-4e6e-bfd8-2531f88343d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, config: dict):\n",
    "        self.data_keys = set(['mnist', 'fashionmnist', 'cifar', 'svhn'])\n",
    "        self.config = config\n",
    "        self.labeled_ids = []\n",
    "        self.unlabeled_ids = []\n",
    "        self.image_tensors = []\n",
    "        self.labels = []\n",
    "        self.counter = 0\n",
    "    \n",
    "    def prepare(self, in_data='mnist', out_data=['cifar', 'svhn', 'fashionmnist'], indata_size=5000, outdata_size=1700, label_ratio=0.02):\n",
    "        # Prepare OOD data\n",
    "        for k in out_data:\n",
    "            dataset = config[k]['dataset']\n",
    "            transforms = TransformTwice(config[k]['transforms'])\n",
    "            n_outlabels = int(outdata_size * label_ratio)\n",
    "            dataset_ids = np.random.choice(len(dataset), outdata_size, replace=False)\n",
    "            dataset_labeled_ids = set(np.random.choice(dataset_ids, n_outlabels, replace=False))\n",
    "            # u, c = np.unique(dataset_labeled_ids, return_counts=True)\n",
    "            # dup = u[c > 1]\n",
    "            # print(dup)\n",
    "            for idx in dataset_ids:\n",
    "                img = dataset[idx][0]\n",
    "                img_tensor = transforms(img)\n",
    "                self.image_tensors.append(img_tensor)\n",
    "                if idx in dataset_labeled_ids:\n",
    "                    self.labeled_ids.append(self.counter)\n",
    "                    self.labels.append(1)\n",
    "                else:\n",
    "                    self.unlabeled_ids.append(self.counter)\n",
    "                    self.labels.append(0)\n",
    "                self.counter += 1\n",
    "            print(len(self.labeled_ids))\n",
    "            print(f'{k} dataset processed...')\n",
    "        \n",
    "        # Prepare ID data\n",
    "        dataset = config[in_data]['dataset']\n",
    "        transforms = TransformTwice(config[k]['transforms'])\n",
    "        n_inlabels = int(indata_size * label_ratio)\n",
    "        dataset_ids = np.random.choice(len(dataset), indata_size, replace=False)\n",
    "        dataset_labeled_ids = set(np.random.choice(dataset_ids, n_inlabels, replace=False))\n",
    "        for idx in dataset_ids:\n",
    "            img = dataset[idx][0]\n",
    "            img_tensor = transforms(img)\n",
    "            self.image_tensors.append(img_tensor)\n",
    "            if idx in dataset_labeled_ids:\n",
    "                self.labeled_ids.append(self.counter)\n",
    "                self.labels.append(1)\n",
    "            else:\n",
    "                self.unlabeled_ids.append(self.counter)\n",
    "                self.labels.append(0)\n",
    "            self.counter += 1\n",
    "        print(len(self.labeled_ids))\n",
    "        print(f'{in_data} dataset processed...')\n",
    "        \n",
    "        random.shuffle(self.labeled_ids)\n",
    "        random.shuffle(self.unlabeled_ids)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_tensors)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.image_tensors[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "941c118c-c611-4633-a341-ec192018a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLDataset():\n",
    "    def __init__(self, config: dict):\n",
    "        self.data_keys = set(['mnist', 'fashionmnist', 'cifar', 'svhn'])\n",
    "        self.config = config\n",
    "        self.image_tensors = []\n",
    "        self.labels = []\n",
    "    \n",
    "    def prepare(self, in_data='mnist', indata_size=600, outdata_size=200):\n",
    "        print(self.data_keys)\n",
    "        self.data_keys.remove(in_data)\n",
    "        # Prepare OOD data\n",
    "        for k in self.data_keys:\n",
    "            dataset = config[k]['dataset']\n",
    "            transforms = config[k]['transforms']\n",
    "            for i, (img, _) in enumerate(dataset):\n",
    "                if i == outdata_size:\n",
    "                    break\n",
    "                img_tensor = transforms(img)\n",
    "                self.image_tensors.append(img_tensor)\n",
    "            self.labels += [0] * outdata_size\n",
    "        \n",
    "        # Prepare ID data\n",
    "        dataset = config[in_data]['dataset']\n",
    "        transforms = config[in_data]['transforms']\n",
    "        for i, (img, _) in enumerate(dataset):\n",
    "            if i == indata_size:\n",
    "                break\n",
    "            img_tensor = transforms(img)\n",
    "            self.image_tensors.append(img_tensor)\n",
    "        self.labels += [1] * indata_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_tensors)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.image_tensors[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "84b9a022-be6a-4b52-8ffb-a43303b35f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_to_three_channel = transforms.Lambda(lambda img: img.expand(3,*img.shape[1:]))\n",
    "\n",
    "svhn_transforms = transforms.Compose([\n",
    "                    # transforms.Grayscale(),\n",
    "                    transforms.RandomCrop(32, padding=4),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize((32,32))\n",
    "                ])\n",
    "\n",
    "mnist_transforms = transforms.Compose([\n",
    "                   transforms.RandomCrop(32, padding=4),\n",
    "                   transforms.RandomHorizontalFlip(),\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Resize((32,32)),\n",
    "                   transform_to_three_channel\n",
    "                ])\n",
    "\n",
    "fashionmnist_transforms = transforms.Compose([\n",
    "                    transforms.RandomCrop(32, padding=4),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize((32,32)),\n",
    "                    transform_to_three_channel\n",
    "                ])\n",
    "\n",
    "cifar_transforms = transforms.Compose([\n",
    "                    transforms.RandomCrop(32, padding=4),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    # transforms.Grayscale(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize((32,32))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f96446aa-9056-4afc-9d1a-e6a8af4eeb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config['svhn'] = {}\n",
    "config['svhn']['dataset'] = svhn_dataset\n",
    "config['svhn']['transforms'] = svhn_transforms\n",
    "\n",
    "config['mnist'] = {}\n",
    "config['mnist']['dataset'] = mnist_dataset\n",
    "config['mnist']['transforms'] = mnist_transforms\n",
    "\n",
    "config['fashionmnist'] = {}\n",
    "config['fashionmnist']['dataset'] = fashionmnist_dataset\n",
    "config['fashionmnist']['transforms'] = fashionmnist_transforms\n",
    "\n",
    "config['cifar'] = {}\n",
    "config['cifar']['dataset'] = cifar_dataset\n",
    "config['cifar']['transforms'] = cifar_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "be1ffb39-b419-4c66-9100-0dfc81b4c611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "mnist dataset processed...\n",
      "6000\n",
      "svhn dataset processed...\n",
      "9000\n",
      "fashionmnist dataset processed...\n",
      "18000\n",
      "cifar dataset processed...\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset(config)\n",
    "ds.prepare(in_data='cifar', out_data=['mnist', 'svhn', 'fashionmnist'], indata_size=45000, outdata_size=15000, label_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9927f078-8ec6-4809-b273-ba677c1e043c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90000"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds.unlabeled_ids) + len(ds.labeled_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8e6bcfaf-974b-4f0a-9b23-ddef934cad66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /scratch/rm5708/ml/ML_Project/data/test_32x32.mat\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "svhn_test_dataset = SVHN(root=data_dir, split='test', download=True)\n",
    "mnist_test_dataset = MNIST(root=data_dir, train=False, download=True)\n",
    "fashionmnist_test_dataset = FashionMNIST(root=data_dir, train=False, download=True)\n",
    "cifar_test_dataset = CIFAR10(root=data_dir, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c460804b-f229-49d3-b362-68948025a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = {}\n",
    "\n",
    "test_config['svhn'] = {}\n",
    "test_config['svhn']['dataset'] = svhn_test_dataset\n",
    "test_config['svhn']['transforms'] = svhn_transforms\n",
    "\n",
    "test_config['mnist'] = {}\n",
    "test_config['mnist']['dataset'] = mnist_test_dataset\n",
    "test_config['mnist']['transforms'] = mnist_transforms\n",
    "\n",
    "test_config['fashionmnist'] = {}\n",
    "test_config['fashionmnist']['dataset'] = fashionmnist_test_dataset\n",
    "test_config['fashionmnist']['transforms'] = fashionmnist_transforms\n",
    "\n",
    "test_config['cifar'] = {}\n",
    "test_config['cifar']['dataset'] = cifar_test_dataset\n",
    "test_config['cifar']['transforms'] = cifar_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "da501a38-eef3-4564-add8-434a2fdbc2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fashionmnist', 'svhn', 'cifar', 'mnist'}\n"
     ]
    }
   ],
   "source": [
    "test_ds = SLDataset(test_config)\n",
    "test_ds.prepare(in_data='cifar', indata_size=1200, outdata_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2a8aea62-a23d-4b3c-8d6b-50f7a2f4b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_sampler = LabeledUnlabeledBatchSampler(ds.labeled_ids, ds.unlabeled_ids, 32, 32)\n",
    "trainloader = torch.utils.data.DataLoader(ds, batch_sampler=train_batch_sampler, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(test_ds, batch_size=64, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f553a657-6dc7-49ba-b50a-05ae687af69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balle balle\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for batch in trainloader:\n",
    "    # print(len(batch))\n",
    "    print(batch[0][0].shape)\n",
    "    print(batch[0][1].shape)\n",
    "    print(batch[1].shape)\n",
    "    # cv2.imshow('image window1', batch[0][0])\n",
    "    # cv2.imshow('image window2', batch[1][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "524191b2-a35e-48d9-aafa-9bed0e5f0f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "-1\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for batch in testloader:\n",
    "    print(len(batch))\n",
    "    print(batch[0].get_device())\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "508e39ed-2a8c-45eb-95a5-8d4e483539e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "cls_num_list = [6000, 45000]\n",
    "\n",
    "class LDAMLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, cls_num_list, max_m=0.5, weight=None, s=30):\n",
    "        super(LDAMLoss, self).__init__()\n",
    "        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n",
    "        m_list = m_list * (max_m / np.max(m_list))\n",
    "        m_list = torch.cuda.FloatTensor(m_list)\n",
    "        self.m_list = m_list\n",
    "        assert s > 0\n",
    "        self.s = s\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        index = torch.zeros_like(x, dtype=torch.uint8)\n",
    "        index.scatter_(1, target.data.view(-1, 1), 1)\n",
    "        \n",
    "        index_float = index.type(torch.cuda.FloatTensor)\n",
    "        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n",
    "        batch_m = batch_m.view((-1, 1))\n",
    "        x_m = x - batch_m\n",
    "    \n",
    "        output = torch.where(index, x_m, x)\n",
    "        return F.cross_entropy(self.s*output, target, weight=self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2124dd42-191d-454d-b2bb-51705c0466f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (3, 32, 32)\n",
    "flow = 'ResidualFlow'\n",
    "model_cfg = getattr(flow_ssl, flow)\n",
    "net = model_cfg(in_channels=img_shape[0], num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "65002dfb-566c-4820-add7-8ffcf1bf0869",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flow in [\"iCNN3d\", \"iResnetProper\",\"SmallResidualFlow\",\"ResidualFlow\",\"MNISTResidualFlow\"]:\n",
    "    net = net.flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f5920588-44f1-46f1-90ce-575b5529cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.train_flows.utils import train_utils\n",
    "\n",
    "means = 'random'\n",
    "means_r = 1.0\n",
    "cov_std = 1.0\n",
    "# img_shape = (1, 32, 32)\n",
    "device = 'cuda'\n",
    "n_classes = 2\n",
    "\n",
    "net = net.to(device)\n",
    "r = means_r\n",
    "cov_std = torch.ones((n_classes)) * cov_std\n",
    "cov_std = cov_std.to(device)\n",
    "means = train_utils.get_means(means, num_means=n_classes, r=means_r, trainloader=trainloader, \n",
    "                        shape=img_shape, device=device, net=net)\n",
    "means_init = means.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9487a807-bb50-4650-b26f-e294679e7af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: tensor([[-0.7030, -1.0039,  1.2775,  ...,  0.1396,  0.6088,  1.6998],\n",
      "        [ 0.4860,  0.0813,  1.5526,  ...,  1.5942,  0.8390,  0.1382]],\n",
      "       device='cuda:0')\n",
      "Cov std: tensor([1., 1.], device='cuda:0')\n",
      "Pairwise dists: [[ 0.         78.45355722]\n",
      " [78.45355722  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "print(\"Means:\", means)\n",
    "print(\"Cov std:\", cov_std)\n",
    "means_np = means.cpu().numpy()\n",
    "print(\"Pairwise dists:\", cdist(means_np, means_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "dd372806-894b-4d04-bac1-9266b46015fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using learnable means\n"
     ]
    }
   ],
   "source": [
    "from flow_ssl.distributions import SSLGaussMixture\n",
    "from flow_ssl import FlowLoss\n",
    "\n",
    "means_trainable = True\n",
    "covs_trainable = True\n",
    "weights_trainable = True\n",
    "\n",
    "if means_trainable:\n",
    "    print(\"Using learnable means\")\n",
    "    means = torch.tensor(means_np, requires_grad=True, device=device)\n",
    "\n",
    "prior = SSLGaussMixture(means, device=device)\n",
    "prior.weights.requires_grad = weights_trainable\n",
    "prior.inv_cov_stds.requires_grad = covs_trainable\n",
    "loss_fn = FlowLoss(prior)\n",
    "sup_loss_fn = LDAMLoss(cls_num_list, s=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "416efc52-ebbf-4011-8055-15feb3e81734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.train_flows.utils import norm_util\n",
    "import torch.optim as optim\n",
    "\n",
    "param_groups = norm_util.get_param_groups(net, 0.0, norm_suffix='weight_g')\n",
    "\n",
    "optimizer = optim.Adam(param_groups, lr=5e-4, weight_decay=1e-2)\n",
    "opt_gmm = optim.Adam([prior.means, prior.weights, prior.inv_cov_stds], lr=1e-4, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "11c3f709-4854-4f51-95c1-9d0ab84a5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir='./')\n",
    "device = 'cuda' if torch.cuda.is_available() and len([0]) > 0 else 'cpu'\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "85e9c466-b4f6-4f86-a329-455280c72332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(epoch, net, testloader, device, loss_fn, writer=None, postfix=\"\",\n",
    "                    show_classification_images=False, confusion=False):\n",
    "    net.eval()\n",
    "    loss_meter = shell_util.AverageMeter()\n",
    "    jaclogdet_meter = shell_util.AverageMeter()\n",
    "    acc_meter = shell_util.AverageMeter()\n",
    "    all_pred_labels = []\n",
    "    all_xs = []\n",
    "    all_ys = []\n",
    "    all_zs = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(testloader.dataset)) as progress_bar:\n",
    "            for x, y in testloader:\n",
    "                all_xs.append(x.data.numpy())\n",
    "                all_ys.append(y.data.numpy())\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                z = net(x)\n",
    "                all_zs.append(z.cpu().data.numpy())\n",
    "                sldj = net.logdet()\n",
    "                loss = loss_fn(z, y=y, sldj=sldj)\n",
    "                loss_meter.update(loss.item(), x.size(0))\n",
    "                jaclogdet_meter.update(sldj.mean().item(), x.size(0))\n",
    "\n",
    "                preds = loss_fn.prior.classify(z.reshape((len(z), -1)))\n",
    "                preds = preds.reshape(y.shape)\n",
    "                all_pred_labels.append(preds.cpu().data.numpy())\n",
    "                acc = (preds == y).float().mean().item()\n",
    "                acc_meter.update(acc, x.size(0))\n",
    "\n",
    "                progress_bar.set_postfix(loss=loss_meter.avg,\n",
    "                                     bpd=optim_util.bits_per_dim(x, loss_meter.avg),\n",
    "                                     acc=acc_meter.avg)\n",
    "                progress_bar.update(x.size(0))\n",
    "    all_pred_labels = np.hstack(all_pred_labels)\n",
    "    all_xs = np.vstack(all_xs)\n",
    "    all_zs = np.vstack(all_zs)\n",
    "    all_ys = np.hstack(all_ys)\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.add_scalar(\"test/loss{}\".format(postfix), loss_meter.avg, epoch)\n",
    "        writer.add_scalar(\"test/acc{}\".format(postfix), acc_meter.avg, epoch)\n",
    "        writer.add_scalar(\"test/bpd{}\".format(postfix), optim_util.bits_per_dim(x, loss_meter.avg), epoch)\n",
    "        writer.add_scalar(\"test/jaclogdet{}\".format(postfix), jaclogdet_meter.avg, epoch)\n",
    "\n",
    "        for cls in range(np.max(all_pred_labels)+1):\n",
    "            num_imgs_cls = (all_pred_labels==cls).sum()\n",
    "            writer.add_scalar(\"test_clustering/num_class_{}_{}\".format(cls,postfix), \n",
    "                    num_imgs_cls, epoch)\n",
    "            if num_imgs_cls == 0:\n",
    "                writer.add_scalar(\"test_clustering/num_class_{}_{}\".format(cls,postfix), \n",
    "                    0., epoch)\n",
    "                continue\n",
    "            writer.add_histogram('label_distributions/num_class_{}_{}'.format(cls,postfix), \n",
    "                    all_ys[all_pred_labels==cls], epoch)\n",
    "\n",
    "            writer.add_histogram(\n",
    "                'distance_distributions/num_class_{}'.format(cls),\n",
    "                torch.norm(torch.tensor(all_zs[all_pred_labels==cls]) - loss_fn.prior.means[cls].cpu(), p=2, dim=1),\n",
    "                epoch\n",
    "            )\n",
    "\n",
    "            if show_classification_images:\n",
    "                images_cls = all_xs[all_pred_labels==cls][:10]\n",
    "                images_cls = torch.from_numpy(images_cls).float()\n",
    "                images_cls_concat = torchvision.utils.make_grid(\n",
    "                        images_cls, nrow=2, padding=2, pad_value=255)\n",
    "                writer.add_image(\"test_clustering/class_{}\".format(cls), \n",
    "                        images_cls_concat)\n",
    "\n",
    "        if confusion:\n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "            cm = confusion_matrix(all_ys, all_pred_labels)\n",
    "            cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "            sns.heatmap(cm, annot=True, cmap=plt.cm.Blues)\n",
    "            plt.ylabel('True label')\n",
    "            plt.xlabel('Predicted label')\n",
    "            conf_img = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
    "            conf_img = torch.tensor(conf_img.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
    "            writer.add_image(\"confusion\", conf_img, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c5aebe9b-7dd6-4e51-8ae8-24ce144978cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_labels = len(ds.labeled_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9e14cd2d-44e1-4f81-8ba5-b868870dc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(net, prior, batch_size, cls, device, sample_shape):\n",
    "    \"\"\"Sample from RealNVP model.\n",
    "    Args:\n",
    "        net (torch.nn.DataParallel): The RealNVP model wrapped in DataParallel.\n",
    "        batch_size (int): Number of samples to generate.\n",
    "        device (torch.device): Device to use.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        if cls is not None:\n",
    "            z = prior.sample((batch_size,), gaussian_id=cls)\n",
    "        else:\n",
    "            z = prior.sample((batch_size,))\n",
    "        x = net.inverse(z)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c129e139-d9c4-48b9-8d47-cd070b329153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.train_flows.utils import optim_util\n",
    "\n",
    "def train(epoch, net, trainloader, device, optimizer, opt_gmm, loss_fn,\n",
    "          label_weight, max_grad_norm, consistency_weight,\n",
    "          writer, sup_loss_fn, use_unlab=True,  acc_train_all_labels=False,\n",
    "          ):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    loss_meter = shell_util.AverageMeter()\n",
    "    loss_unsup_meter = shell_util.AverageMeter()\n",
    "    loss_nll_meter = shell_util.AverageMeter()\n",
    "    loss_consistency_meter = shell_util.AverageMeter()\n",
    "    jaclogdet_meter = shell_util.AverageMeter()\n",
    "    acc_meter = shell_util.AverageMeter()\n",
    "    acc_all_meter = shell_util.AverageMeter()\n",
    "    with tqdm(total=2*total_labels) as progress_bar:\n",
    "        for (x1, x2), y in trainloader:\n",
    "\n",
    "            x1 = x1.to(device)\n",
    "            if not acc_train_all_labels:\n",
    "                y = y.to(device)\n",
    "            else:\n",
    "                y, y_all_lab = y[:, 0], y[:, 1]\n",
    "                y = y.to(device)\n",
    "                y_all_lab = y_all_lab.to(device)\n",
    "\n",
    "            labeled_mask = (y != NO_LABEL)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            opt_gmm.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                x2 = x2.to(device)\n",
    "                # z21 = net(x2)\n",
    "                # z22 = net(transform(x2))\n",
    "                # y22 = classify(z22)\n",
    "                # l_cons = FlowLoss(z21, y22)\n",
    "                # print(x2.get_device(), next(net.parameters()).is_cuda)\n",
    "                z2 = net(x2)\n",
    "                z2 = z2.detach()\n",
    "                pred2 = loss_fn.prior.classify(z2.reshape((len(z2), -1)))\n",
    "\n",
    "            z1 = net(x1)\n",
    "            sldj = net.logdet()\n",
    "\n",
    "            z_all = z1.reshape((len(z1), -1))\n",
    "            z_labeled = z_all[labeled_mask]\n",
    "            y_labeled = y[labeled_mask]\n",
    "\n",
    "            logits_all = loss_fn.prior.class_logits(z_all)\n",
    "            logits_labeled = logits_all[labeled_mask]\n",
    "            loss_nll = F.cross_entropy(logits_labeled, y_labeled)\n",
    "            # loss_nll = sup_loss_fn(logits_labeled, y_labeled)\n",
    "            # print(loss_nll)\n",
    "            # loss_nll = loss_nll.mean()\n",
    "            # print(loss_nll)\n",
    "\n",
    "            if use_unlab:\n",
    "                loss_unsup = loss_fn(z1, sldj=sldj)\n",
    "                # print(loss_unsup)\n",
    "                loss = loss_nll * label_weight + loss_unsup\n",
    "            else:\n",
    "                loss_unsup = torch.tensor([0.])\n",
    "                loss = loss_nll\n",
    "\n",
    "            # consistency loss\n",
    "            loss_consistency = loss_fn(z1, sldj=sldj, y=pred2)\n",
    "            loss = loss + loss_consistency * consistency_weight\n",
    "\n",
    "            loss.backward()\n",
    "            optim_util.clip_grad_norm(optimizer, max_grad_norm)\n",
    "            optimizer.step()\n",
    "            opt_gmm.step()\n",
    "\n",
    "            preds_all = torch.argmax(logits_all, dim=1)\n",
    "            preds = preds_all[labeled_mask]\n",
    "            acc = (preds == y_labeled).float().mean().item()\n",
    "            if acc_train_all_labels:\n",
    "                acc_all = (preds_all == y_all_lab).float().mean().item()\n",
    "            else:\n",
    "                acc_all = acc\n",
    "\n",
    "            acc_meter.update(acc, x1.size(0))\n",
    "            acc_all_meter.update(acc_all, x1.size(0))\n",
    "            loss_meter.update(loss.item(), x1.size(0))\n",
    "            loss_unsup_meter.update(loss_unsup.item(), x1.size(0))\n",
    "            loss_nll_meter.update(loss_nll.item(), x1.size(0))\n",
    "            jaclogdet_meter.update(sldj.mean().item(), x1.size(0))\n",
    "            loss_consistency_meter.update(loss_consistency.item(), x1.size(0))\n",
    "\n",
    "            progress_bar.set_postfix(loss=loss_meter.avg,\n",
    "                                     bpd=optim_util.bits_per_dim(x1, loss_unsup_meter.avg),\n",
    "                                     acc=acc_meter.avg,\n",
    "                                     acc_all=acc_all_meter.avg)\n",
    "            progress_bar.update(y_labeled.size(0))\n",
    "\n",
    "    x1_img = torchvision.utils.make_grid(x1[:10], nrow=2 , padding=2, pad_value=255)\n",
    "    x2_img = torchvision.utils.make_grid(x2[:10], nrow=2 , padding=2, pad_value=255)\n",
    "    writer.add_image(\"data/x1\", x1_img)\n",
    "    writer.add_image(\"data/x2\", x2_img)\n",
    "\n",
    "    writer.add_scalar(\"train/loss\", loss_meter.avg, epoch)\n",
    "    writer.add_scalar(\"train/loss_unsup\", loss_unsup_meter.avg, epoch)\n",
    "    writer.add_scalar(\"train/loss_nll\", loss_nll_meter.avg, epoch)\n",
    "    writer.add_scalar(\"train/jaclogdet\", jaclogdet_meter.avg, epoch)\n",
    "    writer.add_scalar(\"train/acc\", acc_meter.avg, epoch)\n",
    "    writer.add_scalar(\"train/acc_all\", acc_all_meter.avg, epoch)\n",
    "    writer.add_scalar(\"train/bpd\", optim_util.bits_per_dim(x1, loss_unsup_meter.avg), epoch)\n",
    "    writer.add_scalar(\"train/loss_consistency\", loss_consistency_meter.avg, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb4663-d856-41b4-8e60-b657bba607bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0db4ea084264129a8ae10e36c02bb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balle balle\n",
      "Saving...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77946a9ce7ef4c209874817bd7ee6000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-27997766/ipykernel_3806802/1258797901.py:78: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  conf_img = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
      "/state/partition1/job-27997766/ipykernel_3806802/1258797901.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  conf_img = torch.tensor(conf_img.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
      "/state/partition1/job-27997766/ipykernel_3806802/3055084958.py:74: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  img_data = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
      "/state/partition1/job-27997766/ipykernel_3806802/3055084958.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_data = torch.tensor(img_data.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
      "/state/partition1/job-27997766/ipykernel_3806802/3055084958.py:79: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  writer.add_scalar(\"train_gmm/weight/{}\".format(i), F.softmax(prior.weights)[i], epoch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b74f4dfd9fa4cf39531caa83753d202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balle balle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n",
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff53498c13664f57b4d5ec80832fbf3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balle balle\n",
      "Saving...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe47aaf541845bdbca90702191e0722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-27997766/ipykernel_3806802/1258797901.py:78: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  conf_img = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
      "/state/partition1/job-27997766/ipykernel_3806802/1258797901.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  conf_img = torch.tensor(conf_img.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
      "/state/partition1/job-27997766/ipykernel_3806802/3055084958.py:74: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  img_data = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
      "/state/partition1/job-27997766/ipykernel_3806802/3055084958.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_data = torch.tensor(img_data.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
      "/state/partition1/job-27997766/ipykernel_3806802/3055084958.py:79: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  writer.add_scalar(\"train_gmm/weight/{}\".format(i), F.softmax(prior.weights)[i], epoch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00193d4765e3423aaea8df94e26d0f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balle balle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n",
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2b878bbd2b4e75b3e307542b316b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balle balle\n",
      "Saving...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357f1ba89d104599b98204662dc93b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-27997766/ipykernel_3806802/1258797901.py:78: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  conf_img = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
      "/state/partition1/job-27997766/ipykernel_3806802/1258797901.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  conf_img = torch.tensor(conf_img.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
      "/state/partition1/job-27997766/ipykernel_3806802/3055084958.py:74: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  img_data = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
      "/state/partition1/job-27997766/ipykernel_3806802/3055084958.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_data = torch.tensor(img_data.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
      "/state/partition1/job-27997766/ipykernel_3806802/3055084958.py:79: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  writer.add_scalar(\"train_gmm/weight/{}\".format(i), F.softmax(prior.weights)[i], epoch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab5f364687c462cb7ec72fe751e856f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balle balle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n",
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80da2da98bd74c3ebb7d14ef3e1f3368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balle balle\n",
      "Saving...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6b98d0c15d44cdb33c5843f6daa871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-27997766/ipykernel_3806802/1258797901.py:78: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  conf_img = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
      "/state/partition1/job-27997766/ipykernel_3806802/1258797901.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  conf_img = torch.tensor(conf_img.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
      "/state/partition1/job-27997766/ipykernel_3806802/3055084958.py:74: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  img_data = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
      "/state/partition1/job-27997766/ipykernel_3806802/3055084958.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_data = torch.tensor(img_data.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
      "/state/partition1/job-27997766/ipykernel_3806802/3055084958.py:79: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  writer.add_scalar(\"train_gmm/weight/{}\".format(i), F.softmax(prior.weights)[i], epoch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e957efe78344c6ea3cb9f927b5d22f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balle balle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n",
      "/scratch/rm5708/ml/ML_Project/flowgmm-public/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfb43a08759470e835e294e75848ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balle balle\n"
     ]
    }
   ],
   "source": [
    "from experiments.train_flows.utils import shell_util\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "NO_LABEL = -1\n",
    "schedule = None\n",
    "n_epochs = 10\n",
    "lr = 5e-4\n",
    "lr_gmm = 1e-4\n",
    "consistency_weight = 0.01\n",
    "consistency_rampup = 1\n",
    "label_weight = 1.0\n",
    "max_grad_norm = 100.0\n",
    "save_freq = 2\n",
    "ckptdir = './'\n",
    "eval_freq = 2\n",
    "confusion = True\n",
    "num_samples = 50\n",
    "\n",
    "def linear_rampup(final_value, epoch, num_epochs, start_epoch=0):\n",
    "    t = (epoch - start_epoch + 1) / num_epochs\n",
    "    if t > 1:\n",
    "        t = 1.\n",
    "    return t * final_value\n",
    "\n",
    "for epoch in range(start_epoch, n_epochs):\n",
    "    cons_weight = linear_rampup(consistency_weight, epoch, consistency_rampup, start_epoch)\n",
    "    \n",
    "    writer.add_scalar(\"hypers/learning_rate\", lr, epoch)\n",
    "    writer.add_scalar(\"hypers/learning_rate_gmm\", lr_gmm, epoch)\n",
    "    writer.add_scalar(\"hypers/consistency_weight\", cons_weight, epoch)\n",
    "\n",
    "    train(epoch, net, trainloader, device, optimizer, opt_gmm, loss_fn,\n",
    "          label_weight, max_grad_norm, cons_weight,\n",
    "          writer, sup_loss_fn, use_unlab=True)\n",
    "\n",
    "    # Save checkpoint\n",
    "    if (epoch % save_freq == 0):\n",
    "        print('Saving...')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'means': prior.means,\n",
    "        }\n",
    "        os.makedirs(ckptdir, exist_ok=True)\n",
    "        torch.save(state, os.path.join(ckptdir, str(epoch)+'.pt'))\n",
    "\n",
    "    # Save samples and data\n",
    "    if epoch % eval_freq == 0:\n",
    "        test_classifier(epoch, net, testloader, device, loss_fn, writer, confusion=confusion)\n",
    "        # if args.swa:\n",
    "        #     optimizer.swap_swa_sgd() \n",
    "        #     print(\"updating bn\")\n",
    "        #     SWA.bn_update(bn_loader, net)\n",
    "        #     utils.test_classifier(epoch, net, testloader, device, loss_fn, \n",
    "        #             writer, postfix=\"_swa\")\n",
    "\n",
    "        z_means = prior.means\n",
    "        data_means = net.inverse(z_means)\n",
    "        z_mean_imgs = torchvision.utils.make_grid(\n",
    "                z_means.reshape((n_classes, *img_shape)), nrow=2)\n",
    "        data_mean_imgs = torchvision.utils.make_grid(\n",
    "                data_means.reshape((n_classes, *img_shape)), nrow=2)\n",
    "        writer.add_image(\"z_means\", z_mean_imgs, epoch)\n",
    "        writer.add_image(\"data_means\", data_mean_imgs, epoch)\n",
    "\n",
    "        means_np = prior.means.detach().cpu().numpy()\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cdist(means_np, means_np))\n",
    "        img_data = torch.tensor(np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=''))\n",
    "        img_data = torch.tensor(img_data.reshape(fig.canvas.get_width_height()[::-1] + (3,))).transpose(0, 2).transpose(1, 2)\n",
    "        writer.add_image(\"mean_dists\", img_data, epoch)\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            writer.add_scalar(\"train_gmm/weight/{}\".format(i), F.softmax(prior.weights)[i], epoch)\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            writer.add_scalar(\"train_gmm/cov/{}\".format(i), F.softplus(prior.inv_cov_stds[i])**2, epoch)\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            writer.add_scalar(\"train_gmm/mean_dist_init/{}\".format(i), torch.norm(prior.means[i]-means_init[i], 2), epoch)\n",
    "\n",
    "        images = []\n",
    "        for i in range(n_classes):\n",
    "            images_cls = sample(net, loss_fn.prior, num_samples // n_classes,\n",
    "                                      cls=i, device=device, sample_shape=img_shape)\n",
    "            images.append(images_cls)\n",
    "            images_cls_concat = torchvision.utils.make_grid(\n",
    "                    images_cls, nrow=2, padding=2, pad_value=255)\n",
    "            writer.add_image(\"samples/class_\"+str(i), images_cls_concat)\n",
    "        images = torch.cat(images)\n",
    "        os.makedirs(os.path.join(ckptdir, 'samples'), exist_ok=True)\n",
    "        images_concat = torchvision.utils.make_grid(images, nrow=num_samples //  n_classes , padding=2, pad_value=255)\n",
    "        os.makedirs(ckptdir, exist_ok=True)\n",
    "        torchvision.utils.save_image(images_concat, \n",
    "                                    os.path.join(ckptdir, 'samples/epoch_{}.png'.format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a4677551-9a12-4364-abda-5e4931a608b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2846"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds.labeled_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d17aae14-9f2f-4f72-a39f-1e6c61f9369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from checkpoint at ./4.pt\n"
     ]
    }
   ],
   "source": [
    "resume = './4.pt'\n",
    "print('Resuming from checkpoint at', resume)\n",
    "checkpoint = torch.load(resume)\n",
    "# net.load_state_dict(checkpoint['net'])\n",
    "# start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "467d4f02-66fa-4187-8f66-1ec5a1c862ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(checkpoint['net'])\n",
    "start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "81959d05-d08f-4cda-856a-7a2d9038df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "omniglot_transforms = transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Resize((32,32)),\n",
    "                      transform_to_three_channel\n",
    "                    ])\n",
    "\n",
    "omniglot_dataset = Omniglot(root=data_dir, background=True, download=False, transform=omniglot_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "303f1320-a568-4d7f-b58d-0b396b7cb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "first, second = torch.utils.data.random_split(omniglot_dataset, [10000, 9280])\n",
    "omniglot_loader = torch.utils.data.DataLoader(first, batch_size=64, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "997dcce5-56aa-4770-914f-20ec58a98c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b523814d8f064103a8fc63f06aec1ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_xs = []\n",
    "all_ys = []\n",
    "all_zs = []\n",
    "all_pred_labels = []\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(omniglot_loader.dataset)) as progress_bar:\n",
    "        for x, y in omniglot_loader:\n",
    "            all_xs.append(x.data.numpy())\n",
    "            all_ys.append(y.data.numpy())\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            z = net(x)\n",
    "            all_zs.append(z.cpu().data.numpy())\n",
    "            sldj = net.logdet()\n",
    "\n",
    "            preds = loss_fn.prior.classify(z.reshape((len(z), -1)))\n",
    "            preds = preds.reshape(y.shape)\n",
    "            all_pred_labels.append(preds.cpu().data.numpy())\n",
    "            acc = (preds == y).float().mean().item()\n",
    "            progress_bar.update(x.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f9f4d34f-6068-4731-8cc1-bbf343afb0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3841"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.hstack(all_pred_labels) == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38ad452a-fce9-4485-9b1f-ed2f84fcf344",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = SLDataset(test_config)\n",
    "test_ds.prepare(in_data='cifar', indata_size=1000, outdata_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a7c9c29-d7ee-4286-b951-10c85579aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_loader = torch.utils.data.DataLoader(mnist_test_dataset, batch_size=64, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6e57adcc-c2b4-4cd8-8ef0-d4dcf90785f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bc2038ab0b48f7b6e1ca076395b45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_xs = []\n",
    "all_ys = []\n",
    "all_zs = []\n",
    "all_pred_labels = []\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(mnist_loader.dataset)) as progress_bar:\n",
    "        for x, y in mnist_loader:\n",
    "            all_xs.append(x.data.numpy())\n",
    "            all_ys.append(y.data.numpy())\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            z = net(x)\n",
    "            all_zs.append(z.cpu().data.numpy())\n",
    "            sldj = net.logdet()\n",
    "\n",
    "            preds = loss_fn.prior.classify(z.reshape((len(z), -1)))\n",
    "            preds = preds.reshape(y.shape)\n",
    "            all_pred_labels.append(preds.cpu().data.numpy())\n",
    "            acc = (preds == y).float().mean().item()\n",
    "            progress_bar.update(x.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "92ecd823-cf62-4298-a8a0-647a8e6e3310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9061"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.hstack(all_pred_labels) == all_ys).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8cfc90ec-a35c-4de2-b621-161c3c1c0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ys = np.zeros((10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ae1d6b0-82e4-41cc-bfa6-87d5407bf75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "35b3f19d-3273-4cfe-a34a-e384b655834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, precision_recall_curve, roc_curve\n",
    "\n",
    "def auroc(preds, labels, pos_label=1):\n",
    "    \"\"\"Calculate and return the area under the ROC curve using unthresholded predictions on the data and a binary true label.\n",
    "    \n",
    "    preds: array, shape = [n_samples]\n",
    "           Target normality scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.\n",
    "           i.e.: an high value means sample predicted \"normal\", belonging to the positive class\n",
    "           \n",
    "    labels: array, shape = [n_samples]\n",
    "            True binary labels in range {0, 1} or {-1, 1}.\n",
    "    pos_label: label of the positive class (1 by default)\n",
    "    \"\"\"\n",
    "    fpr, tpr, _ = roc_curve(labels, preds, pos_label=pos_label)\n",
    "    return auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d98091c2-a849-44b9-b970-b6a67d241343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/envs/full_time/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1018: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc(np.hstack(all_pred_labels), all_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b632b25-4866-4b44-a1cb-71484908bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset():\n",
    "    def __init__(self, config: dict):\n",
    "        self.data_keys = set(['mnist', 'fashionmnist', 'cifar', 'svhn'])\n",
    "        self.config = config\n",
    "        self.image_tensors = []\n",
    "        self.labels = []\n",
    "    \n",
    "    def prepare(self, in_data='cifar', out_data=['svhn'], indata_size=600, outdata_size=600):\n",
    "        # Prepare OOD data\n",
    "        s = outdata_size // len(out_data)\n",
    "        for k in out_data:\n",
    "            dataset = config[k]['dataset']\n",
    "            transforms = config[k]['transforms']\n",
    "            for i, (img, _) in enumerate(dataset):\n",
    "                if i == outdata_size:\n",
    "                    break\n",
    "                img_tensor = transforms(img)\n",
    "                self.image_tensors.append(img_tensor)\n",
    "            self.labels += [0] * outdata_size\n",
    "        \n",
    "        # Prepare ID data\n",
    "        dataset = config[in_data]['dataset']\n",
    "        transforms = config[in_data]['transforms']\n",
    "        for i, (img, _) in enumerate(dataset):\n",
    "            if i == indata_size:\n",
    "                break\n",
    "            img_tensor = transforms(img)\n",
    "            self.image_tensors.append(img_tensor)\n",
    "        self.labels += [1] * indata_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_tensors)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.image_tensors[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb64df03-bdff-4634-9de8-a7e55ff5dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "testds = TestDataset(test_config)\n",
    "testds.prepare(indata_size=1000, outdata_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3252226-825f-4cba-8272-912c6e07e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(testds, batch_size=64, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b28ee2e-de63-4c37-84d3-ac85caba2218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from checkpoint at ./8.pt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for iSequential:\n\tUnexpected key(s) in state_dict: \"1.0.nnet.1.u\", \"1.0.nnet.1.v\", \"1.0.nnet.3.u\", \"1.0.nnet.3.v\", \"1.0.nnet.5.u\", \"1.0.nnet.5.v\", \"2.0.nnet.1.u\", \"2.0.nnet.1.v\", \"2.0.nnet.3.u\", \"2.0.nnet.3.v\", \"2.0.nnet.5.u\", \"2.0.nnet.5.v\", \"3.0.nnet.1.u\", \"3.0.nnet.1.v\", \"3.0.nnet.3.u\", \"3.0.nnet.3.v\", \"3.0.nnet.5.u\", \"3.0.nnet.5.v\", \"4.0.nnet.1.u\", \"4.0.nnet.1.v\", \"4.0.nnet.3.u\", \"4.0.nnet.3.v\", \"4.0.nnet.5.u\", \"4.0.nnet.5.v\", \"5.0.nnet.1.u\", \"5.0.nnet.1.v\", \"5.0.nnet.3.u\", \"5.0.nnet.3.v\", \"5.0.nnet.5.u\", \"5.0.nnet.5.v\", \"6.0.nnet.1.u\", \"6.0.nnet.1.v\", \"6.0.nnet.3.u\", \"6.0.nnet.3.v\", \"6.0.nnet.5.u\", \"6.0.nnet.5.v\", \"7.0.nnet.1.u\", \"7.0.nnet.1.v\", \"7.0.nnet.3.u\", \"7.0.nnet.3.v\", \"7.0.nnet.5.u\", \"7.0.nnet.5.v\", \"8.0.nnet.1.u\", \"8.0.nnet.1.v\", \"8.0.nnet.3.u\", \"8.0.nnet.3.v\", \"8.0.nnet.5.u\", \"8.0.nnet.5.v\", \"9.0.nnet.1.u\", \"9.0.nnet.1.v\", \"9.0.nnet.3.u\", \"9.0.nnet.3.v\", \"9.0.nnet.5.u\", \"9.0.nnet.5.v\", \"10.0.nnet.1.u\", \"10.0.nnet.1.v\", \"10.0.nnet.3.u\", \"10.0.nnet.3.v\", \"10.0.nnet.5.u\", \"10.0.nnet.5.v\", \"11.0.nnet.1.u\", \"11.0.nnet.1.v\", \"11.0.nnet.3.u\", \"11.0.nnet.3.v\", \"11.0.nnet.5.u\", \"11.0.nnet.5.v\", \"12.0.nnet.1.u\", \"12.0.nnet.1.v\", \"12.0.nnet.3.u\", \"12.0.nnet.3.v\", \"12.0.nnet.5.u\", \"12.0.nnet.5.v\", \"13.0.nnet.1.u\", \"13.0.nnet.1.v\", \"13.0.nnet.3.u\", \"13.0.nnet.3.v\", \"13.0.nnet.5.u\", \"13.0.nnet.5.v\", \"14.0.nnet.1.u\", \"14.0.nnet.1.v\", \"14.0.nnet.3.u\", \"14.0.nnet.3.v\", \"14.0.nnet.5.u\", \"14.0.nnet.5.v\", \"15.0.nnet.1.u\", \"15.0.nnet.1.v\", \"15.0.nnet.3.u\", \"15.0.nnet.3.v\", \"15.0.nnet.5.u\", \"15.0.nnet.5.v\", \"16.0.nnet.1.u\", \"16.0.nnet.1.v\", \"16.0.nnet.3.u\", \"16.0.nnet.3.v\", \"16.0.nnet.5.u\", \"16.0.nnet.5.v\", \"18.0.nnet.1.u\", \"18.0.nnet.1.v\", \"18.0.nnet.3.u\", \"18.0.nnet.3.v\", \"18.0.nnet.5.u\", \"18.0.nnet.5.v\", \"19.0.nnet.1.u\", \"19.0.nnet.1.v\", \"19.0.nnet.3.u\", \"19.0.nnet.3.v\", \"19.0.nnet.5.u\", \"19.0.nnet.5.v\", \"20.0.nnet.1.u\", \"20.0.nnet.1.v\", \"20.0.nnet.3.u\", \"20.0.nnet.3.v\", \"20.0.nnet.5.u\", \"20.0.nnet.5.v\", \"21.0.nnet.1.u\", \"21.0.nnet.1.v\", \"21.0.nnet.3.u\", \"21.0.nnet.3.v\", \"21.0.nnet.5.u\", \"21.0.nnet.5.v\", \"22.0.nnet.1.u\", \"22.0.nnet.1.v\", \"22.0.nnet.3.u\", \"22.0.nnet.3.v\", \"22.0.nnet.5.u\", \"22.0.nnet.5.v\", \"23.0.nnet.1.u\", \"23.0.nnet.1.v\", \"23.0.nnet.3.u\", \"23.0.nnet.3.v\", \"23.0.nnet.5.u\", \"23.0.nnet.5.v\", \"24.0.nnet.1.u\", \"24.0.nnet.1.v\", \"24.0.nnet.3.u\", \"24.0.nnet.3.v\", \"24.0.nnet.5.u\", \"24.0.nnet.5.v\", \"25.0.nnet.1.u\", \"25.0.nnet.1.v\", \"25.0.nnet.3.u\", \"25.0.nnet.3.v\", \"25.0.nnet.5.u\", \"25.0.nnet.5.v\", \"26.0.nnet.1.u\", \"26.0.nnet.1.v\", \"26.0.nnet.3.u\", \"26.0.nnet.3.v\", \"26.0.nnet.5.u\", \"26.0.nnet.5.v\", \"27.0.nnet.1.u\", \"27.0.nnet.1.v\", \"27.0.nnet.3.u\", \"27.0.nnet.3.v\", \"27.0.nnet.5.u\", \"27.0.nnet.5.v\", \"28.0.nnet.1.u\", \"28.0.nnet.1.v\", \"28.0.nnet.3.u\", \"28.0.nnet.3.v\", \"28.0.nnet.5.u\", \"28.0.nnet.5.v\", \"29.0.nnet.1.u\", \"29.0.nnet.1.v\", \"29.0.nnet.3.u\", \"29.0.nnet.3.v\", \"29.0.nnet.5.u\", \"29.0.nnet.5.v\", \"30.0.nnet.1.u\", \"30.0.nnet.1.v\", \"30.0.nnet.3.u\", \"30.0.nnet.3.v\", \"30.0.nnet.5.u\", \"30.0.nnet.5.v\", \"31.0.nnet.1.u\", \"31.0.nnet.1.v\", \"31.0.nnet.3.u\", \"31.0.nnet.3.v\", \"31.0.nnet.5.u\", \"31.0.nnet.5.v\", \"32.0.nnet.1.u\", \"32.0.nnet.1.v\", \"32.0.nnet.3.u\", \"32.0.nnet.3.v\", \"32.0.nnet.5.u\", \"32.0.nnet.5.v\", \"33.0.nnet.1.u\", \"33.0.nnet.1.v\", \"33.0.nnet.3.u\", \"33.0.nnet.3.v\", \"33.0.nnet.5.u\", \"33.0.nnet.5.v\", \"35.0.nnet.1.u\", \"35.0.nnet.1.v\", \"35.0.nnet.3.u\", \"35.0.nnet.3.v\", \"35.0.nnet.5.u\", \"35.0.nnet.5.v\", \"36.0.nnet.1.u\", \"36.0.nnet.1.v\", \"36.0.nnet.3.u\", \"36.0.nnet.3.v\", \"36.0.nnet.5.u\", \"36.0.nnet.5.v\", \"37.0.nnet.1.u\", \"37.0.nnet.1.v\", \"37.0.nnet.3.u\", \"37.0.nnet.3.v\", \"37.0.nnet.5.u\", \"37.0.nnet.5.v\", \"38.0.nnet.1.u\", \"38.0.nnet.1.v\", \"38.0.nnet.3.u\", \"38.0.nnet.3.v\", \"38.0.nnet.5.u\", \"38.0.nnet.5.v\", \"39.0.nnet.1.u\", \"39.0.nnet.1.v\", \"39.0.nnet.3.u\", \"39.0.nnet.3.v\", \"39.0.nnet.5.u\", \"39.0.nnet.5.v\", \"40.0.nnet.1.u\", \"40.0.nnet.1.v\", \"40.0.nnet.3.u\", \"40.0.nnet.3.v\", \"40.0.nnet.5.u\", \"40.0.nnet.5.v\", \"41.0.nnet.1.u\", \"41.0.nnet.1.v\", \"41.0.nnet.3.u\", \"41.0.nnet.3.v\", \"41.0.nnet.5.u\", \"41.0.nnet.5.v\", \"42.0.nnet.1.u\", \"42.0.nnet.1.v\", \"42.0.nnet.3.u\", \"42.0.nnet.3.v\", \"42.0.nnet.5.u\", \"42.0.nnet.5.v\", \"43.0.nnet.1.u\", \"43.0.nnet.1.v\", \"43.0.nnet.3.u\", \"43.0.nnet.3.v\", \"43.0.nnet.5.u\", \"43.0.nnet.5.v\", \"44.0.nnet.1.u\", \"44.0.nnet.1.v\", \"44.0.nnet.3.u\", \"44.0.nnet.3.v\", \"44.0.nnet.5.u\", \"44.0.nnet.5.v\", \"45.0.nnet.1.u\", \"45.0.nnet.1.v\", \"45.0.nnet.3.u\", \"45.0.nnet.3.v\", \"45.0.nnet.5.u\", \"45.0.nnet.5.v\", \"46.0.nnet.1.u\", \"46.0.nnet.1.v\", \"46.0.nnet.3.u\", \"46.0.nnet.3.v\", \"46.0.nnet.5.u\", \"46.0.nnet.5.v\", \"47.0.nnet.1.u\", \"47.0.nnet.1.v\", \"47.0.nnet.3.u\", \"47.0.nnet.3.v\", \"47.0.nnet.5.u\", \"47.0.nnet.5.v\", \"48.0.nnet.1.u\", \"48.0.nnet.1.v\", \"48.0.nnet.3.u\", \"48.0.nnet.3.v\", \"48.0.nnet.5.u\", \"48.0.nnet.5.v\", \"49.0.nnet.1.u\", \"49.0.nnet.1.v\", \"49.0.nnet.3.u\", \"49.0.nnet.3.v\", \"49.0.nnet.5.u\", \"49.0.nnet.5.v\", \"50.0.nnet.1.u\", \"50.0.nnet.1.v\", \"50.0.nnet.3.u\", \"50.0.nnet.3.v\", \"50.0.nnet.5.u\", \"50.0.nnet.5.v\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResuming from checkpoint at\u001b[39m\u001b[38;5;124m'\u001b[39m, resume)\n\u001b[1;32m      3\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(resume)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m start_epoch \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/full_time/lib/python3.8/site-packages/torch/nn/modules/module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1599\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1600\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1601\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1605\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for iSequential:\n\tUnexpected key(s) in state_dict: \"1.0.nnet.1.u\", \"1.0.nnet.1.v\", \"1.0.nnet.3.u\", \"1.0.nnet.3.v\", \"1.0.nnet.5.u\", \"1.0.nnet.5.v\", \"2.0.nnet.1.u\", \"2.0.nnet.1.v\", \"2.0.nnet.3.u\", \"2.0.nnet.3.v\", \"2.0.nnet.5.u\", \"2.0.nnet.5.v\", \"3.0.nnet.1.u\", \"3.0.nnet.1.v\", \"3.0.nnet.3.u\", \"3.0.nnet.3.v\", \"3.0.nnet.5.u\", \"3.0.nnet.5.v\", \"4.0.nnet.1.u\", \"4.0.nnet.1.v\", \"4.0.nnet.3.u\", \"4.0.nnet.3.v\", \"4.0.nnet.5.u\", \"4.0.nnet.5.v\", \"5.0.nnet.1.u\", \"5.0.nnet.1.v\", \"5.0.nnet.3.u\", \"5.0.nnet.3.v\", \"5.0.nnet.5.u\", \"5.0.nnet.5.v\", \"6.0.nnet.1.u\", \"6.0.nnet.1.v\", \"6.0.nnet.3.u\", \"6.0.nnet.3.v\", \"6.0.nnet.5.u\", \"6.0.nnet.5.v\", \"7.0.nnet.1.u\", \"7.0.nnet.1.v\", \"7.0.nnet.3.u\", \"7.0.nnet.3.v\", \"7.0.nnet.5.u\", \"7.0.nnet.5.v\", \"8.0.nnet.1.u\", \"8.0.nnet.1.v\", \"8.0.nnet.3.u\", \"8.0.nnet.3.v\", \"8.0.nnet.5.u\", \"8.0.nnet.5.v\", \"9.0.nnet.1.u\", \"9.0.nnet.1.v\", \"9.0.nnet.3.u\", \"9.0.nnet.3.v\", \"9.0.nnet.5.u\", \"9.0.nnet.5.v\", \"10.0.nnet.1.u\", \"10.0.nnet.1.v\", \"10.0.nnet.3.u\", \"10.0.nnet.3.v\", \"10.0.nnet.5.u\", \"10.0.nnet.5.v\", \"11.0.nnet.1.u\", \"11.0.nnet.1.v\", \"11.0.nnet.3.u\", \"11.0.nnet.3.v\", \"11.0.nnet.5.u\", \"11.0.nnet.5.v\", \"12.0.nnet.1.u\", \"12.0.nnet.1.v\", \"12.0.nnet.3.u\", \"12.0.nnet.3.v\", \"12.0.nnet.5.u\", \"12.0.nnet.5.v\", \"13.0.nnet.1.u\", \"13.0.nnet.1.v\", \"13.0.nnet.3.u\", \"13.0.nnet.3.v\", \"13.0.nnet.5.u\", \"13.0.nnet.5.v\", \"14.0.nnet.1.u\", \"14.0.nnet.1.v\", \"14.0.nnet.3.u\", \"14.0.nnet.3.v\", \"14.0.nnet.5.u\", \"14.0.nnet.5.v\", \"15.0.nnet.1.u\", \"15.0.nnet.1.v\", \"15.0.nnet.3.u\", \"15.0.nnet.3.v\", \"15.0.nnet.5.u\", \"15.0.nnet.5.v\", \"16.0.nnet.1.u\", \"16.0.nnet.1.v\", \"16.0.nnet.3.u\", \"16.0.nnet.3.v\", \"16.0.nnet.5.u\", \"16.0.nnet.5.v\", \"18.0.nnet.1.u\", \"18.0.nnet.1.v\", \"18.0.nnet.3.u\", \"18.0.nnet.3.v\", \"18.0.nnet.5.u\", \"18.0.nnet.5.v\", \"19.0.nnet.1.u\", \"19.0.nnet.1.v\", \"19.0.nnet.3.u\", \"19.0.nnet.3.v\", \"19.0.nnet.5.u\", \"19.0.nnet.5.v\", \"20.0.nnet.1.u\", \"20.0.nnet.1.v\", \"20.0.nnet.3.u\", \"20.0.nnet.3.v\", \"20.0.nnet.5.u\", \"20.0.nnet.5.v\", \"21.0.nnet.1.u\", \"21.0.nnet.1.v\", \"21.0.nnet.3.u\", \"21.0.nnet.3.v\", \"21.0.nnet.5.u\", \"21.0.nnet.5.v\", \"22.0.nnet.1.u\", \"22.0.nnet.1.v\", \"22.0.nnet.3.u\", \"22.0.nnet.3.v\", \"22.0.nnet.5.u\", \"22.0.nnet.5.v\", \"23.0.nnet.1.u\", \"23.0.nnet.1.v\", \"23.0.nnet.3.u\", \"23.0.nnet.3.v\", \"23.0.nnet.5.u\", \"23.0.nnet.5.v\", \"24.0.nnet.1.u\", \"24.0.nnet.1.v\", \"24.0.nnet.3.u\", \"24.0.nnet.3.v\", \"24.0.nnet.5.u\", \"24.0.nnet.5.v\", \"25.0.nnet.1.u\", \"25.0.nnet.1.v\", \"25.0.nnet.3.u\", \"25.0.nnet.3.v\", \"25.0.nnet.5.u\", \"25.0.nnet.5.v\", \"26.0.nnet.1.u\", \"26.0.nnet.1.v\", \"26.0.nnet.3.u\", \"26.0.nnet.3.v\", \"26.0.nnet.5.u\", \"26.0.nnet.5.v\", \"27.0.nnet.1.u\", \"27.0.nnet.1.v\", \"27.0.nnet.3.u\", \"27.0.nnet.3.v\", \"27.0.nnet.5.u\", \"27.0.nnet.5.v\", \"28.0.nnet.1.u\", \"28.0.nnet.1.v\", \"28.0.nnet.3.u\", \"28.0.nnet.3.v\", \"28.0.nnet.5.u\", \"28.0.nnet.5.v\", \"29.0.nnet.1.u\", \"29.0.nnet.1.v\", \"29.0.nnet.3.u\", \"29.0.nnet.3.v\", \"29.0.nnet.5.u\", \"29.0.nnet.5.v\", \"30.0.nnet.1.u\", \"30.0.nnet.1.v\", \"30.0.nnet.3.u\", \"30.0.nnet.3.v\", \"30.0.nnet.5.u\", \"30.0.nnet.5.v\", \"31.0.nnet.1.u\", \"31.0.nnet.1.v\", \"31.0.nnet.3.u\", \"31.0.nnet.3.v\", \"31.0.nnet.5.u\", \"31.0.nnet.5.v\", \"32.0.nnet.1.u\", \"32.0.nnet.1.v\", \"32.0.nnet.3.u\", \"32.0.nnet.3.v\", \"32.0.nnet.5.u\", \"32.0.nnet.5.v\", \"33.0.nnet.1.u\", \"33.0.nnet.1.v\", \"33.0.nnet.3.u\", \"33.0.nnet.3.v\", \"33.0.nnet.5.u\", \"33.0.nnet.5.v\", \"35.0.nnet.1.u\", \"35.0.nnet.1.v\", \"35.0.nnet.3.u\", \"35.0.nnet.3.v\", \"35.0.nnet.5.u\", \"35.0.nnet.5.v\", \"36.0.nnet.1.u\", \"36.0.nnet.1.v\", \"36.0.nnet.3.u\", \"36.0.nnet.3.v\", \"36.0.nnet.5.u\", \"36.0.nnet.5.v\", \"37.0.nnet.1.u\", \"37.0.nnet.1.v\", \"37.0.nnet.3.u\", \"37.0.nnet.3.v\", \"37.0.nnet.5.u\", \"37.0.nnet.5.v\", \"38.0.nnet.1.u\", \"38.0.nnet.1.v\", \"38.0.nnet.3.u\", \"38.0.nnet.3.v\", \"38.0.nnet.5.u\", \"38.0.nnet.5.v\", \"39.0.nnet.1.u\", \"39.0.nnet.1.v\", \"39.0.nnet.3.u\", \"39.0.nnet.3.v\", \"39.0.nnet.5.u\", \"39.0.nnet.5.v\", \"40.0.nnet.1.u\", \"40.0.nnet.1.v\", \"40.0.nnet.3.u\", \"40.0.nnet.3.v\", \"40.0.nnet.5.u\", \"40.0.nnet.5.v\", \"41.0.nnet.1.u\", \"41.0.nnet.1.v\", \"41.0.nnet.3.u\", \"41.0.nnet.3.v\", \"41.0.nnet.5.u\", \"41.0.nnet.5.v\", \"42.0.nnet.1.u\", \"42.0.nnet.1.v\", \"42.0.nnet.3.u\", \"42.0.nnet.3.v\", \"42.0.nnet.5.u\", \"42.0.nnet.5.v\", \"43.0.nnet.1.u\", \"43.0.nnet.1.v\", \"43.0.nnet.3.u\", \"43.0.nnet.3.v\", \"43.0.nnet.5.u\", \"43.0.nnet.5.v\", \"44.0.nnet.1.u\", \"44.0.nnet.1.v\", \"44.0.nnet.3.u\", \"44.0.nnet.3.v\", \"44.0.nnet.5.u\", \"44.0.nnet.5.v\", \"45.0.nnet.1.u\", \"45.0.nnet.1.v\", \"45.0.nnet.3.u\", \"45.0.nnet.3.v\", \"45.0.nnet.5.u\", \"45.0.nnet.5.v\", \"46.0.nnet.1.u\", \"46.0.nnet.1.v\", \"46.0.nnet.3.u\", \"46.0.nnet.3.v\", \"46.0.nnet.5.u\", \"46.0.nnet.5.v\", \"47.0.nnet.1.u\", \"47.0.nnet.1.v\", \"47.0.nnet.3.u\", \"47.0.nnet.3.v\", \"47.0.nnet.5.u\", \"47.0.nnet.5.v\", \"48.0.nnet.1.u\", \"48.0.nnet.1.v\", \"48.0.nnet.3.u\", \"48.0.nnet.3.v\", \"48.0.nnet.5.u\", \"48.0.nnet.5.v\", \"49.0.nnet.1.u\", \"49.0.nnet.1.v\", \"49.0.nnet.3.u\", \"49.0.nnet.3.v\", \"49.0.nnet.5.u\", \"49.0.nnet.5.v\", \"50.0.nnet.1.u\", \"50.0.nnet.1.v\", \"50.0.nnet.3.u\", \"50.0.nnet.3.v\", \"50.0.nnet.5.u\", \"50.0.nnet.5.v\". "
     ]
    }
   ],
   "source": [
    "resume = './8.pt'\n",
    "print('Resuming from checkpoint at', resume)\n",
    "checkpoint = torch.load(resume)\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d505e3-234c-4ba0-b933-184b26861d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
